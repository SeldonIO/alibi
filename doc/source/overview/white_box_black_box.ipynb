{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54251b59-422f-444e-b936-74d45ee1cd23",
   "metadata": {},
   "source": [
    "# White-box and black-box models\n",
    "\n",
    "Explainer algorithms can be categorised in many ways (see [this table](algorithms.md#model-explanations)), but perhaps the most fundamental one is whether they work with **white-box** or **black-box** models.\n",
    "\n",
    "**White-box** is a term used for any model that the explainer method can \"look inside\" and manipulate arbitrarily. In the context of `alibi` this category of models corresponds to Python objects that represent models, for example instances of `sklearn.base.BaseEstimator`, `tensorflow.keras.Model`, `torch.nn.Module` etc. The exact type of the white-box model in question enables different white-box explainer methods. For example, `tensorflow` and `torch` models are *gradient-based* which enables *gradient-based* explainer methods such as [Integrated Gradients](../methods/IntegratedGradients.ipynb) [^ig] whilst various types of tree-based models are supported by [TreeShap](../methods/TreeSHAP.ipynb).\n",
    "\n",
    "[^ig]: At the time of writing `IntegratedGradients` only supports `tensorflow` models.\n",
    "\n",
    "On the other hand, a **black-box** model describes any model that the explainer method may not inspect and modify arbitrarily. The only interaction with the model is via calling its `predict` function (or similar) on data and receiving predictions back. In the context of `alibi` black-box models have a concrete definitionâ€”they are functions that take in a `numpy` array representing data and return a `numpy` array representing a prediction. Using [type hints](https://docs.python.org/3/library/typing.html) we can define a general black-box model (also referred to as a *prediction function*) to be of type `Callable[[np.ndarray], np.ndarray]`[^bb-input]. Explainers that expect black-box models as input are very flexible as *any* type of function that conforms to the expected type can be explained by black-box explainers.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Note\n",
    "\n",
    "In addition to the expected type, black-box models **must** be compatible with batch prediction. I.e. `alibi` explainers assume that the first dimension of the input array is always batch.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "Warning\n",
    "\n",
    "There is currently one exception to the black-box interface: the `AnchorText` explainer expects the prediction function to be of type `Callable[[List[str], np.ndarray]`, i.e. the model is expected to work on batches of raw text (here `List[str]` indicates a batch of text strings). See [this example](../examples/anchor_text_movie.nblink) for more information.\n",
    "    \n",
    "</div>\n",
    "\n",
    "[^bb-input]: Note that this definition limits black-box models to be *single-input* and *single-output* which are what most black-box `alibi` explainers can handle. In the general case the definition can be extended to *multi-input* and *multi-output* models, i.e. taking in and/or returning multiple arrays.\n",
    "\n",
    "\n",
    "## Wrapping white-box models into black-box models\n",
    "Models in Python all start out as white-box models (i.e. custom Python objects from some modelling library like `sklearn` or `tensorflow`). However, to be used with explainers that expect a black-box prediction function, the user has to define a prediction function that conforms to the black-box definition given above. Here we give a few common examples and some pointers about creating a black-box prediction function from a white-box model. In what follows we distinguish between the original white-box `model` and the wrapped black-box `predictor` function.\n",
    "\n",
    "### Scikit-learn models\n",
    "All `sklearn` models expose a `predict` method that already conforms to the black-box function interface defined above which makes it easy to create black-box predictors:\n",
    "\n",
    "```python\n",
    "predictor = model.predict\n",
    "explainer = SomeExplainer(predictor, **kwargs)\n",
    "```\n",
    "\n",
    "In some cases for classifiers it may be more appropriate to expose the `predict_proba` or `decision_function` method instead of `predict`, see an example on [ALE for classifiers](../examples/ale_classification.nblink).\n",
    "\n",
    "### Tensorflow models\n",
    "Tensorflow models (specifically instances of `tensorflow.keras.Model`) expose a `predict` method that takes in `numpy` arrays and returns predictions as `numpy` arrays[^tf-call]:\n",
    "\n",
    "```python\n",
    "predictor = model.predict\n",
    "explainer = SomeExplainer(predictor), **kwargs)\n",
    "```\n",
    "\n",
    "\n",
    "### Pytorch models\n",
    "Pytorch models (specifically instances of `torch.nn.Module`) expect and return instances of `torch.Tensor` from the `forward` method, thus we need to do a bit more work to define the `predictor` black-box function:\n",
    "\n",
    "```python\n",
    "def predictor(X: np.ndarray) -> np.ndarray:\n",
    "    X = torch.as_tensor(X, dtype=dtype, device=device)\n",
    "    return model.forward(X).detach().numpy()\n",
    "```\n",
    "\n",
    "Note that there are a few differences with `tensorflow` models:\n",
    " - Explicit conversion to a tensor with a specific `dtype`. Whilst `tensorflow`  handles this internally when `predict` is called, for `torch` we need to do this manually.\n",
    " - Explicit device selection for the tensor. This is an important step as `numpy` arrays are limited to cpu and if your model is on a gpu it will expect its input tensors to be on a gpu.\n",
    " - Explicit conversion of prediction tensor to `numpy`. Here we detach the output from the gradient graph (as gradient information is not needed) and convert to a `numpy` array.\n",
    "\n",
    "If you are using [Pytorch Lightning](https://www.pytorchlightning.ai) to create `torch` models, then the `dtype` and `device` can be retrieved as attributes of your `LightningModule`, see [here](https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html). \n",
    "\n",
    "### General models\n",
    "Given the above examples, the pattern for defining a black-box predictor from a white-box model is clear: define a `predictor` function that manipulates the inputs to and outputs from the underlying model in a way that conforms to the black-box model interface `alibi` expects:\n",
    "\n",
    "```python\n",
    "def predictor(X: np.ndarray) -> np.ndarray:\n",
    "    inp = transform_input(X)\n",
    "    output = model(inp) # or call the model-specific prediction method\n",
    "    output = transform_output(output)\n",
    "    return output\n",
    "\n",
    "explainer = SomeExplainer(predictor, **kwargs)\n",
    "```\n",
    "\n",
    "Here `transform_input` and `transform_output` are general user-defined functions that appropriately transform the input `numpy` arrays in a format that the model expects and transform the output predictions into a `numpy` array so that `predictor` is an `alibi` compatible black-box function.\n",
    "\n",
    "[^tf-call]: This is in contrast to the `__call__` and `call` methods which expect and return `tensorflow.Tensor` objects. However, using `__call__` may be preferable for performance in [some cases](https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict) (this would require transforming inputs and outputs similar to the `torch` example).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
