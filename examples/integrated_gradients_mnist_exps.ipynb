{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "from tensorflow.keras.layers import Activation, Conv2D, Conv2DTranspose, Dense, Dropout\n",
    "from tensorflow.keras.layers import Flatten, Input, InputLayer, Reshape, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from alibi.explainers import IntegratedGradients\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%set_env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (60000, 10) (10000, 28, 28, 1) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "train, test = tf.keras.datasets.mnist.load_data()\n",
    "X_train, y_train = train\n",
    "X_test, y_test = test\n",
    "\n",
    "X_train = X_train.reshape(-1, 28, 28, 1).astype('float64') / 255\n",
    "X_test = X_test.reshape(-1, 28, 28, 1).astype('float64') / 255\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.argmax(y_test, axis=1)\n",
    "train_labels = np.argmax(y_train, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch_X_train = torch.from_numpy(X_train.reshape(X_train.shape[0], 1, 28, 28)).type(torch.LongTensor)\n",
    "torch_y_train = torch.from_numpy(train_labels).type(torch.LongTensor) # data type is long\n",
    "\n",
    "torch_X_test = torch.from_numpy(X_test.reshape(X_test.shape[0], 1, 28, 28)).type(torch.LongTensor)\n",
    "torch_y_test = torch.from_numpy(test_labels).type(torch.LongTensor) # data type is long\n",
    "\n",
    "train = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
    "test = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "BATCH_SIZE = 128\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=2)\n",
    "        self.conv1_drop = nn.Dropout2d(0.3)\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=2)\n",
    "        self.conv2_drop = nn.Dropout2d(0.3)\n",
    "        self.fc2 = nn.Linear(1152, 10)\n",
    "        self.conv3_drop = nn.Dropout2d(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = self.conv1_drop(x)\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = self.conv2_drop(x)\n",
    "        x = x.view(-1, 32 * 6 * 6)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x)\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 1, 8, 4, 6, 8, 7, 7, 0, 5, 2, 2, 6, 4, 8, 7, 0, 4, 0, 7, 7, 9, 5, 1,\n",
      "        9, 6, 1, 2, 7, 3, 4, 9, 9, 6, 7, 9, 7, 1, 7, 2, 3, 7, 8, 5, 7, 6, 7, 1,\n",
      "        9, 7, 2, 1, 8, 3, 4, 3, 0, 8, 3, 0, 4, 3, 7, 6, 0, 5, 6, 9, 3, 6, 3, 0,\n",
      "        6, 0, 7, 1, 1, 3, 1, 3, 1, 6, 7, 4, 1, 7, 2, 7, 1, 5, 3, 9, 0, 7, 3, 2])\n",
      "tensor(16838)\n",
      "Epoch : 0, acc : 0.28063333333333335\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2ce48230af02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-2ce48230af02>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, train_loader)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_X_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_y_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf115/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf115/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "def fit(model, train_loader):\n",
    "    optimizer = torch.optim.Adam(model.parameters())#,lr=0.001, betas=(0.9,0.999))\n",
    "    error = nn.CrossEntropyLoss()\n",
    "    EPOCHS = 10\n",
    "    model.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "        correct = 0\n",
    "        tot = 0\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "            var_X_batch = Variable(X_batch).float()\n",
    "            var_y_batch = Variable(y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(var_X_batch)\n",
    "            loss = error(output, var_y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Total correct predictions\n",
    "            predicted = torch.max(output.data, 1)[1] \n",
    "            correct += (predicted == var_y_batch).sum()\n",
    "            tot += len(predicted)\n",
    "            #print(correct)\n",
    "        print(predicted)\n",
    "        print(correct)\n",
    "        print('Epoch : {}, acc : {}'.format(epoch, correct.detach().numpy() / tot))\n",
    "                \n",
    "                \n",
    "fit(net, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (X_test_batch, y_test_batch) in enumerate(test_loader):\n",
    "    var_X_batch = Variable(X_test_batch).float()\n",
    "    var_y_batch = Variable(y_test_batch) \n",
    "    preds = net(var_X_batch)\n",
    "    print(preds, var_y_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_mnist_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 - 8s - loss: 0.4905 - acc: 0.8446 - val_loss: 0.1223 - val_acc: 0.9652\n",
      "Epoch 2/2\n",
      "60000/60000 - 5s - loss: 0.1659 - acc: 0.9483 - val_loss: 0.0724 - val_acc: 0.9777\n"
     ]
    }
   ],
   "source": [
    "filepath = './model_mnist/'  # change to directory where model is downloaded\n",
    "if load_mnist_model:\n",
    "    model = tf.keras.models.load_model(os.path.join(filepath, 'model.h5'))\n",
    "else:\n",
    "    # define model\n",
    "    inputs = Input(shape=(X_train.shape[1:]), dtype=tf.float64)\n",
    "    x = Conv2D(64, 2, padding='same', activation='relu')(inputs)\n",
    "    x = MaxPooling2D(pool_size=2)(x)\n",
    "    x = Dropout(.3)(x)\n",
    "    \n",
    "    x = Conv2D(32, 2, padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=2)(x)\n",
    "    x = Dropout(.3)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(.5)(x)\n",
    "    logits = Dense(10, name='logits')(x)\n",
    "    outputs = Activation('softmax', name='softmax')(logits)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # train model\n",
    "    model.fit(X_train,\n",
    "              y_train,\n",
    "              epochs=2,\n",
    "              batch_size=256,\n",
    "              verbose=2,\n",
    "              validation_data=(X_test, y_test)\n",
    "              )\n",
    "    if not os.path.exists(filepath):\n",
    "        os.makedirs(filepath)\n",
    "    model.save(os.path.join(filepath, 'model.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 50\n",
    "method = \"gausslegendre\"\n",
    "return_convergence_delta = True\n",
    "return_predictions = False\n",
    "ig  = IntegratedGradients(model,layer=model.layers[2],\n",
    "                          n_steps=n_steps, \n",
    "                          method=method,\n",
    "                          return_convergence_delta=return_convergence_delta, \n",
    "                          return_predictions=return_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_samples = 10\n",
    "bs = 10\n",
    "X_test_red = X_test[:nb_samples]\n",
    "test_labels_red = test_labels[:nb_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = ig.explain(X_test_red, \n",
    "                         baselines=None, \n",
    "                         target=test_labels_red, \n",
    "                         internal_batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'IntegratedGradients',\n",
       " 'type': ['tensorflow', 'keras'],\n",
       " 'explanations': ['local', 'global'],\n",
       " 'params': {'n_steps': 50,\n",
       "  'method': 'gausslegendre',\n",
       "  'return_convergence_delta': True,\n",
       "  'return_predictions': False}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanation.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributions = explanation.data['attributions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 14, 14, 64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5ff2607190>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('True label',test_labels[i])\n",
    "plt.imshow(np.squeeze(X_test[i]), cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(np.squeeze(attributions[i]), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf115]",
   "language": "python",
   "name": "conda-env-tf115-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
