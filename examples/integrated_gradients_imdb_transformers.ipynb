{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%set_env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated gradients for text classification on the IMDB dataset using transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies: tensorflow_datasets, transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we apply the integrated gradients method to a transformer model fine tuned for sentiment analysis on the IMDB dataset. In text classification models, integrated gradients define an attribution value for each word in the input sentence. The attributions are calculated considering the integral of the model  gradients with respect to the input word embedding layer of the transformer along a straight path from a baseline instance $x^\\prime$ to the input instance $x.$ A description of the method can be found [here](https://docs.seldon.io/projects/alibi/en/latest/methods/IntegratedGradients.html). Integrated gradients was originally proposed in Sundararajan et al., [\"Axiomatic Attribution for Deep Networks\"](https://arxiv.org/abs/1703.01365)\n",
    "\n",
    "The IMDB data set contains 50K movie reviews labelled as positive or negative. \n",
    "We train a convolutional neural network classifier with a single 1-d convolutional layer followed by a fully connected layer on top of a transformer model. In other words, the output embeddings of the transformer are used as features by the convolutional network. The reviews in the dataset are truncated at 100 words and each word is represented by 768-dimesional word embedding vector. We calculate attributions for the elements of the input embedding layer of the transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version:  2.3.1\n",
      "Eager execution enabled:  True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Conv1D, GlobalMaxPooling1D, Dropout \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow_datasets as tfds\n",
    "from transformers import BertTokenizerFast, TFBertModel, BertConfig\n",
    "from alibi.explainers import IntegratedGradients\n",
    "import matplotlib.pyplot as plt\n",
    "print('TF version: ', tf.__version__)\n",
    "print('Eager execution enabled: ', tf.executing_eagerly()) # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_reviews(reviews):\n",
    "    \n",
    "    REPLACE_NO_SPACE = re.compile(\"[.;:,!\\'?\\\"()\\[\\]]\")\n",
    "    REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "    \n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "def process_sentences(sentence1, tokenizer, max_len):\n",
    "    \n",
    "    z = tokenizer(sentence1, \n",
    "                  add_special_tokens = True, \n",
    "                  padding = 'max_length', \n",
    "                  max_length = max_len, truncation = True,\n",
    "                  return_token_type_ids=True, \n",
    "                  return_attention_mask = True,  \n",
    "                  return_tensors = 'np')\n",
    "    \n",
    "    return [z['input_ids'], z['attention_mask']]\n",
    "\n",
    "def get_tokens_labels(train_test,\n",
    "                      tokenizer,\n",
    "                      dataset='imdb_reviews/plain_text',\n",
    "                      shuffle_files=True,\n",
    "                      max_len=100):\n",
    "    \n",
    "    ds = tfds.load(dataset, \n",
    "                     split=train_test, \n",
    "                     shuffle_files=shuffle_files)\n",
    "    df = tfds.as_dataframe(ds)\n",
    "    df['text'] = df['text'].astype(str)\n",
    "    df['text'] = df['text'].apply(lambda x: x[1:])\n",
    "    X = df['text'].tolist()\n",
    "    X = preprocess_reviews(X)\n",
    "    X = process_sentences(X, tokenizer, max_len)\n",
    "    y = to_categorical(df['label'].values)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the imdb dataset and transforming the plain text into tokes representation using the bert tokenizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "max_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Load dataset info from /home/gio/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
      "INFO:absl:Reusing dataset imdb_reviews (/home/gio/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
      "INFO:absl:Constructing tf.data.Dataset for split train, from /home/gio/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
      "INFO:absl:Load dataset info from /home/gio/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
      "INFO:absl:Reusing dataset imdb_reviews (/home/gio/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
      "INFO:absl:Constructing tf.data.Dataset for split test, from /home/gio/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\", \n",
    "                                              do_lower_case=True)\n",
    "\n",
    "X_train, y_train = get_tokens_labels('train',\n",
    "                                     tokenizer, \n",
    "                                     max_len=max_len)\n",
    "X_test, y_test = get_tokens_labels('test', \n",
    "                                   tokenizer, \n",
    "                                   max_len=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the output embeddings of the transformer model. These embeddings will be used as input features to train the convolutional network sentiment classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator():\n",
    "    for s1, s2, l in zip(X_train[0], X_train[1], y_train):\n",
    "        yield {'input_ids': s1, 'attention_mask': s2}, l\n",
    "        \n",
    "def test_generator():\n",
    "    for s1, s2, l in zip(X_test[0], X_test[1], y_test):\n",
    "        yield {'input_ids': s1, 'attention_mask': s2}, l\n",
    "\n",
    "def get_embeddings(generator, batch_size=50):\n",
    "    dataset = tf.data.Dataset.from_generator(generator,\n",
    "                                             output_types=({'input_ids': tf.int64,\n",
    "                                                              'attention_mask': tf.int64}, \n",
    "                                                             tf.int64))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    embbedings = []\n",
    "\n",
    "    i = 0\n",
    "    for X_batch in dataset:\n",
    "        batch_embeddings = modelBert(X_batch[0])\n",
    "        embbedings.append(batch_embeddings.last_hidden_state.numpy())\n",
    "        i += 1\n",
    "    \n",
    "    return np.concatenate(embbedings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "config = BertConfig.from_pretrained(\"bert-base-uncased\", \n",
    "                                    output_hidden_states=True)\n",
    "modelBert = TFBertModel.from_pretrained('bert-base-uncased', \n",
    "                                        config=config)\n",
    "modelBert.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embbedings = get_embeddings(train_generator)\n",
    "test_embbedings = get_embeddings(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ModelOut` subclassed model includes one convolutional layer and it is trained on the output embeddings of the bert model. The bert model and convolutional model will be combined after training in a end-to-end functional keras model. The bert model is frozen and it is merely used as a features' extractor.\n",
    "\n",
    "If `save_model = True`, a local folder `../model_imdb` will be created and the trained model will be saved in that folder. If the model was previously saved, it can be loaded by setting `load_model = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = False\n",
    "save_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_filters=32\n",
    "dropout_1=0.5\n",
    "dropout_2=0.5 \n",
    "hidden_dims=32\n",
    "batch_size = 128\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelOut(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, \n",
    "                 nb_filters=32,\n",
    "                 dropout_1=0.2,\n",
    "                 dropout_2=0.2, \n",
    "                 hidden_dims=32):\n",
    "        super(ModelOut, self).__init__()\n",
    "        \n",
    "        self.nb_filters = nb_filters\n",
    "        self.dropout_1 = dropout_1\n",
    "        self.dropout_2 = dropout_2\n",
    "        self.hidden_dims = hidden_dims\n",
    "        \n",
    "        self.conv = tf.keras.layers.Conv1D(nb_filters, \n",
    "                                           kernel_size=4, \n",
    "                                           padding=\"valid\")\n",
    "        self.maxpool = tf.keras.layers.GlobalMaxPool1D()\n",
    "        self.dropoutl_1 = tf.keras.layers.Dropout(dropout_1)\n",
    "        self.flat = tf.keras.layers.Flatten()\n",
    "        self.dense_1 =  tf.keras.layers.Dense(hidden_dims, \n",
    "                                              activation='relu', \n",
    "                                              kernel_initializer='normal')\n",
    "        self.dropoutl_2 = tf.keras.layers.Dropout(dropout_2)\n",
    "        self.dense_2 = tf.keras.layers.Dense(2, \n",
    "                                             activation='softmax', \n",
    "                                             kernel_initializer='normal')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.dropoutl_1(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dropoutl_2(x)\n",
    "        x = self.dense_2(x)\n",
    "        return x\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {\"nb_filters\": self.nb_filters,\n",
    "                \"dropout_1\": self.dropout_1,\n",
    "                \"dropout_2\": self.dropout_2, \n",
    "                \"hidden_dims\": self.hidden_dims}\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the convolutional overhead model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "196/196 [==============================] - 8s 43ms/step - loss: 0.5161 - accuracy: 0.7324 - val_loss: 0.3686 - val_accuracy: 0.8323\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 5s 23ms/step - loss: 0.3868 - accuracy: 0.8328 - val_loss: 0.3586 - val_accuracy: 0.8381\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.3521 - accuracy: 0.8465 - val_loss: 0.3431 - val_accuracy: 0.8473\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 4s 23ms/step - loss: 0.3361 - accuracy: 0.8576 - val_loss: 0.3365 - val_accuracy: 0.8502\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 5s 26ms/step - loss: 0.3230 - accuracy: 0.8642 - val_loss: 0.3328 - val_accuracy: 0.8523\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 4s 22ms/step - loss: 0.3022 - accuracy: 0.8735 - val_loss: 0.3339 - val_accuracy: 0.8510\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.2858 - accuracy: 0.8824 - val_loss: 0.3481 - val_accuracy: 0.8486\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 4s 23ms/step - loss: 0.2714 - accuracy: 0.8905 - val_loss: 0.3387 - val_accuracy: 0.8555\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.2593 - accuracy: 0.8945 - val_loss: 0.3418 - val_accuracy: 0.8548\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.2426 - accuracy: 0.9014 - val_loss: 0.3607 - val_accuracy: 0.8533\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.2286 - accuracy: 0.9074 - val_loss: 0.3501 - val_accuracy: 0.8554\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.2201 - accuracy: 0.9104 - val_loss: 0.3657 - val_accuracy: 0.8524\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 5s 26ms/step - loss: 0.2081 - accuracy: 0.9146 - val_loss: 0.3951 - val_accuracy: 0.8449\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.1917 - accuracy: 0.9254 - val_loss: 0.4167 - val_accuracy: 0.8308\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 5s 23ms/step - loss: 0.1862 - accuracy: 0.9261 - val_loss: 0.4281 - val_accuracy: 0.8501\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.1762 - accuracy: 0.9320 - val_loss: 0.4185 - val_accuracy: 0.8493\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.1711 - accuracy: 0.9338 - val_loss: 0.4059 - val_accuracy: 0.8468\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 5s 27ms/step - loss: 0.1610 - accuracy: 0.9378 - val_loss: 0.4048 - val_accuracy: 0.8514\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 4s 22ms/step - loss: 0.1572 - accuracy: 0.9384 - val_loss: 0.4057 - val_accuracy: 0.8525\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 5s 26ms/step - loss: 0.1464 - accuracy: 0.9446 - val_loss: 0.4535 - val_accuracy: 0.8468\n",
      "WARNING:tensorflow:From /home/gio/anaconda3/envs/intgrads/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gio/anaconda3/envs/intgrads/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gio/anaconda3/envs/intgrads/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gio/anaconda3/envs/intgrads/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/gio/intgrads_transformers/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/gio/intgrads_transformers/model/assets\n"
     ]
    }
   ],
   "source": [
    "filepath = './model_imdb/'  # change to directory where model is downloaded\n",
    "\n",
    "if load_model:\n",
    "    model_out = tf.keras.models.load_model(\n",
    "        filepath, custom_objects={\"ModelOut\": ModelOut})\n",
    "else:\n",
    "    model_out = ModelOut(nb_filters=nb_filters,\n",
    "                     dropout_1=dropout_1,\n",
    "                     dropout_2=dropout_2, \n",
    "                     hidden_dims=hidden_dims)\n",
    "    \n",
    "    model_out.compile(optimizer='adam', \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model_out.fit(train_embbedings, y_train, \n",
    "                  validation_data=(test_embbedings, y_test),\n",
    "                  epochs=epochs, \n",
    "                  batch_size=batch_size, \n",
    "                  verbose=1)\n",
    "    if save_model:\n",
    "        model_out.save(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining the bert model with the convolutional overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f4ae049c590>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f4ae049c590>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f4ae049c590>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "input_ids_in = tf.keras.layers.Input(shape=(max_len,), \n",
    "                                     name='input_ids', \n",
    "                                     dtype=tf.int32)\n",
    "attention_masks_in = tf.keras.layers.Input(shape=(max_len,), \n",
    "                                           name='attention_mask', \n",
    "                                           dtype=tf.int32)\n",
    "X = modelBert([input_ids_in, attention_masks_in])[0]\n",
    "X = model_out(X)\n",
    "frozenModelOut = tf.keras.Model(inputs=[input_ids_in, \n",
    "                                        attention_masks_in], \n",
    "                                outputs=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 109482240   input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "model_out (ModelOut)            (None, 2)            99458       tf_bert_model[0][13]             \n",
      "==================================================================================================\n",
      "Total params: 109,581,698\n",
      "Trainable params: 99,458\n",
      "Non-trainable params: 109,482,240\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "frozenModelOut.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate integrated gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The integrated gradients attributions are calculated with respect to the input embedding layer of the bert model for 10 samples from the test set. Since bert uses a word embedding with vector dimensionality of 768 and we have chosen a sequence length of 100 words, the dimensionality of the attributions is (10, 100, 768). In order to obtain a single attribution value for each word, we sum all the attribution values for the 768 elements of each word's vector representation.\n",
    " \n",
    "The default baseline is used in this example which is internally defined as a sequence of zeros. In this case, this corresponds to a sequence of padding characters (**NB:** in general the numerical value corresponding to a \"non-informative\" baseline such as the PAD token will depend on the tokenizer used, make sure that the numerical value of the baseline used corresponds to your desired token value to avoid surprises). The path integral is defined as a straight line from the baseline to the input image. The path is approximated by choosing 50 discrete steps according to the Gauss-Legendre method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the input embeddings layer from the bert model. \n",
    "bl = frozenModelOut.layers[2].get_input_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 50\n",
    "method = \"gausslegendre\"\n",
    "internal_batch_size = 5\n",
    "nb_samples = 10\n",
    "ig  = IntegratedGradients(frozenModelOut,\n",
    "                          layer=bl,\n",
    "                          n_steps=n_steps, \n",
    "                          method=method,\n",
    "                          internal_batch_size=internal_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_sample = [X_test[0][:nb_samples], X_test[1][:nb_samples]]\n",
    "predictions = frozenModelOut(x_test_sample).numpy().argmax(axis=1)\n",
    "explanation = ig.explain(x_test_sample, \n",
    "                         baselines=None, \n",
    "                         target=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'IntegratedGradients',\n",
       " 'type': ['whitebox'],\n",
       " 'explanations': ['local'],\n",
       " 'params': {'method': 'gausslegendre',\n",
       "  'n_steps': 50,\n",
       "  'internal_batch_size': 5,\n",
       "  'layer': None}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metadata from the explanation object\n",
    "explanation.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['attributions', 'X', 'baselines', 'predictions', 'deltas', 'target'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data fields from the explanation object\n",
    "explanation.data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributions shape: (10, 100, 768)\n"
     ]
    }
   ],
   "source": [
    "# Get attributions values from the explanation object\n",
    "attrs = explanation.attributions[0]\n",
    "print('Attributions shape:', attrs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sum attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributions shape: (10, 100)\n"
     ]
    }
   ],
   "source": [
    "attrs = attrs.sum(axis=2)\n",
    "print('Attributions shape:', attrs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "x_i = x_test_sample[0][i]\n",
    "attrs_i = attrs[i]\n",
    "pred = predictions[i]\n",
    "pred_dict = {1: 'Positive review', 0: 'Negative review'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label =  1: Positive review\n"
     ]
    }
   ],
   "source": [
    "print('Predicted label =  {}: {}'.format(pred, pred_dict[pred]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the attributions for the text instance by mapping the values of the attributions onto a matplotlib colormap. Below we define some utility functions for doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "def  hlstr(string, color='white'):\n",
    "    \"\"\"\n",
    "    Return HTML markup highlighting text with the desired color.\n",
    "    \"\"\"\n",
    "    return f\"<mark style=background-color:{color}>{string} </mark>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorize(attrs, cmap='PiYG'):\n",
    "    \"\"\"\n",
    "    Compute hex colors based on the attributions for a single instance.\n",
    "    Uses a diverging colorscale by default and normalizes and scales\n",
    "    the colormap so that colors are consistent with the attributions.\n",
    "    \"\"\"\n",
    "    import matplotlib as mpl\n",
    "    cmap_bound = np.abs(attrs).max()\n",
    "    norm = mpl.colors.Normalize(vmin=-cmap_bound, vmax=cmap_bound)\n",
    "    cmap = mpl.cm.get_cmap(cmap)\n",
    "    \n",
    "    # now compute hex values of colors\n",
    "    colors = list(map(lambda x: mpl.colors.rgb2hex(cmap(norm(x))), attrs))\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we visualize the attribution values (highlighted in the text) having the highest positive attributions. Words with high positive attribution are highlighted in shades of green and words with negative attribution in shades of pink. Stronger shading corresponds to higher attribution values. Positive attributions can be interpreted as increase in probability of the predicted class (\"Positive sentiment\") while negative attributions correspond to decrease in probability of the predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = tokenizer.decode(x_i).split()\n",
    "colors = colorize(attrs_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<mark style=background-color:#dd73ac>[CLS] </mark><mark style=background-color:#e7f5d3>there </mark><mark style=background-color:#ddf1c1>are </mark><mark style=background-color:#fbe7f2>films </mark><mark style=background-color:#ca2f88>that </mark><mark style=background-color:#eca6cf>make </mark><mark style=background-color:#f9eef4>careers </mark><mark style=background-color:#faecf3>for </mark><mark style=background-color:#e795c3>george </mark><mark style=background-color:#fad6ea>romero </mark><mark style=background-color:#bde38d>it </mark><mark style=background-color:#f0b2d7>was </mark><mark style=background-color:#cfebaa>night </mark><mark style=background-color:#f9eef4>of </mark><mark style=background-color:#faedf3>the </mark><mark style=background-color:#f6f7f5>living </mark><mark style=background-color:#f1b5d9>dead </mark><mark style=background-color:#fbd8eb>for </mark><mark style=background-color:#fde2f0>kevin </mark><mark style=background-color:#fce4f0>smith </mark><mark style=background-color:#fde1ef>clerks </mark><mark style=background-color:#f8f5f6>for </mark><mark style=background-color:#eaf5d9>robert </mark><mark style=background-color:#f4f7f0>rodriguez </mark><mark style=background-color:#fce5f1>el </mark><mark style=background-color:#fde1ef>mariachi </mark><mark style=background-color:#faebf3>add </mark><mark style=background-color:#f3bcdd>to </mark><mark style=background-color:#f7f6f7>that </mark><mark style=background-color:#d5579d>list </mark><mark style=background-color:#ecf6de>onur </mark><mark style=background-color:#fce5f1>tukels </mark><mark style=background-color:#f1f6ea>absolutely </mark><mark style=background-color:#f7f7f7>amazing </mark><mark style=background-color:#f4f7f0>ding </mark><mark style=background-color:#e1f3c7>a </mark><mark style=background-color:#f9d1e8>ling </mark><mark style=background-color:#f1f6e8>less </mark><mark style=background-color:#ecf6de>flawless </mark><mark style=background-color:#f4c1df>film </mark><mark style=background-color:#fce5f1>making </mark><mark style=background-color:#fbe9f2>and </mark><mark style=background-color:#eff6e5>as </mark><mark style=background-color:#eca6cf>assured </mark><mark style=background-color:#fad4e9>and </mark><mark style=background-color:#e8f5d5>as </mark><mark style=background-color:#f7cce5>professional </mark><mark style=background-color:#f8f2f5>as </mark><mark style=background-color:#d9f0bc>any </mark><mark style=background-color:#f9f1f5>of </mark><mark style=background-color:#f9f0f5>the </mark><mark style=background-color:#faebf3>aforementioned </mark><mark style=background-color:#ebf6db>movies </mark><mark style=background-color:#e6f5d0>i </mark><mark style=background-color:#8e0152>havent </mark><mark style=background-color:#ecf6de>laughed </mark><mark style=background-color:#eef6e2>this </mark><mark style=background-color:#f9f1f5>hard </mark><mark style=background-color:#f9f0f5>since </mark><mark style=background-color:#f4f7f0>i </mark><mark style=background-color:#f3f6ed>saw </mark><mark style=background-color:#f3bcdd>the </mark><mark style=background-color:#f7f6f7>full </mark><mark style=background-color:#d2ecb0>monty </mark><mark style=background-color:#fad6ea>and </mark><mark style=background-color:#f7f7f7>even </mark><mark style=background-color:#eaf5d9>then </mark><mark style=background-color:#f7f7f6>i </mark><mark style=background-color:#fbe8f2>dont </mark><mark style=background-color:#fddeee>think </mark><mark style=background-color:#fce3f0>i </mark><mark style=background-color:#ddf1c1>laughed </mark><mark style=background-color:#faecf3>quite </mark><mark style=background-color:#fbe7f2>this </mark><mark style=background-color:#f8f4f6>hard </mark><mark style=background-color:#fce5f1>so </mark><mark style=background-color:#f9d1e8>to </mark><mark style=background-color:#f8f5f6>speak </mark><mark style=background-color:#faecf3>tukels </mark><mark style=background-color:#edf6e1>talent </mark><mark style=background-color:#f1f6e8>is </mark><mark style=background-color:#c51d7e>considerable </mark><mark style=background-color:#f7f7f7>ding </mark><mark style=background-color:#f8f2f5>a </mark><mark style=background-color:#f2f6ec>ling </mark><mark style=background-color:#c0e593>less </mark><mark style=background-color:#f7f6f7>is </mark><mark style=background-color:#86c049>so </mark><mark style=background-color:#d75ea1>chock </mark><mark style=background-color:#ddf1c1>full </mark><mark style=background-color:#edf6e1>[SEP] </mark>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\".join(list(map(hlstr, words, colors))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
