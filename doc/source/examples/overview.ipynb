{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0c87744",
   "metadata": {},
   "source": [
    "# Alibi Overview Example\n",
    "\n",
    "This notebook aims to demonstrate each of the explainers Alibi provides on the same model and dataset. Unfortunately, this isn't possible as white-box neural network methods exclude tree-based white-box methods. Hence we will train both a neural network(TensorFlow) and a random forest model on the same dataset and apply the full range of explainers to see what insights we can obtain.\n",
    "\n",
    "The results and code from this notebook are used in the [documentation overview](../overview/high_level.md).\n",
    "\n",
    "This notebook requires the seaborn package for visualization which can be installed via pip:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13814dfa-27d8-424e-8ee4-8687b99fd2d5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Note\n",
    "    \n",
    "To enusre all dependencies are met for this example, you may need to run\n",
    "    \n",
    "```bash\n",
    "pip install alibi[all]\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ed8c1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b42fe771-fbcd-45e0-a613-6d93a0d7e80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 23:10:31.731283: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from io import BytesIO, StringIO\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import os.path\n",
    "\n",
    "import tensorflow as tf\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "FROM_SCRATCH = False\n",
    "TF_MODEL_FNAME = 'tf-clf-wine'\n",
    "RFC_FNAME = 'rfc-wine'\n",
    "ENC_FNAME = 'wine_encoder'\n",
    "DEC_FNAME = 'wine_decoder'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b561fff-7745-4219-bb84-1787cb7a3501",
   "metadata": {},
   "source": [
    "## Preparing the data.\n",
    "\n",
    "We're using the [wine-quality](https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/) dataset, a numeric tabular dataset containing features that refer to the chemical composition of wines and quality ratings. To make this a simple classification task, we bucket all wines with ratings greater than five as good, and the rest we label bad. We also normalize all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07175f7a-df18-435c-8508-2c37b0242322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_wine_ds():\n",
    "    url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "    resp = requests.get(url, timeout=2)\n",
    "    resp.raise_for_status()\n",
    "    string_io = StringIO(resp.content.decode('utf-8'))\n",
    "    return pd.read_csv(string_io, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4927000-30b8-4fe4-84eb-a5d778fa072a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fetch_wine_ds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae34b435-ed6c-4380-ba8b-1005cf7868ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'] = 'bad'\n",
    "df.loc[(df['quality'] > 5), 'class'] = 'good'\n",
    "\n",
    "features = [\n",
    "    'fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "    'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
    "    'pH', 'sulphates', 'alcohol'\n",
    "]\n",
    "\n",
    "df['good'] = 0\n",
    "df['bad'] = 0\n",
    "df.loc[df['class'] == 'good', 'good'] = 1\n",
    "df.loc[df['class'] == 'bad', 'bad'] = 1\n",
    "\n",
    "data = df[features].to_numpy()\n",
    "labels = df[['class','good', 'bad']].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, random_state=0)\n",
    "X_train, X_test = X_train.astype('float32'), X_test.astype('float32')\n",
    "y_train_lab, y_test_lab = y_train[:, 0], y_test[:, 0]\n",
    "y_train, y_test = y_train[:, 1:].astype('float32'), y_test[:, 1:].astype('float32')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a294d4-82f2-4729-ad66-872fd2925f4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Select good wine instance \n",
    "\n",
    "We partition the dataset into good and bad portions and select an instance of interest. I've chosen it to be a good quality wine. \n",
    "\n",
    "**Note** that bad wines are class 1 and correspond to the second model output being high, whereas good wines are class 0 and correspond to the first model output being high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "926bbabd-946b-4ef3-9aec-6e27df923504",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_wines = np.array([a for a, b in zip(X_train, y_train) if b[1] == 1])\n",
    "good_wines = np.array([a for a, b in zip(X_train, y_train) if b[1] == 0])\n",
    "x = np.array([[9.2, 0.36, 0.34, 1.6, 0.062, 5., 12., 0.99667, 3.2, 0.67, 10.5]]) # prechosen instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd1a33a-5a4e-4c6c-a3c8-56776d656fc5",
   "metadata": {},
   "source": [
    "## Training models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3ff7b6-50c7-4e8c-9436-188cefba608d",
   "metadata": {},
   "source": [
    "### Creating an Autoencoder\n",
    "\n",
    "For some of the explainers, we need an autoencoder to check whether example instances are close to the training data distribution or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af5d71d3-729a-4fee-9f5a-b60bbe8dadc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "ENCODING_DIM = 7\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "\n",
    "\n",
    "class AE(keras.Model):\n",
    "    def __init__(self, encoder: keras.Model, decoder: keras.Model, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def call(self, x: tf.Tensor, **kwargs):\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat\n",
    "    \n",
    "def make_ae():\n",
    "    len_input_output = X_train.shape[-1]\n",
    "\n",
    "    encoder = keras.Sequential()\n",
    "    encoder.add(Dense(units=ENCODING_DIM*2, activation=\"relu\", input_shape=(len_input_output, )))\n",
    "    encoder.add(Dense(units=ENCODING_DIM, activation=\"relu\"))\n",
    "\n",
    "    decoder = keras.Sequential()\n",
    "    decoder.add(Dense(units=ENCODING_DIM*2, activation=\"relu\", input_shape=(ENCODING_DIM, )))\n",
    "    decoder.add(Dense(units=len_input_output, activation=\"linear\"))\n",
    "\n",
    "    ae = AE(encoder=encoder, decoder=decoder)\n",
    "\n",
    "    ae.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    history = ae.fit(\n",
    "        scaler.transform(X_train), \n",
    "        scaler.transform(X_train), \n",
    "        batch_size=BATCH_SIZE, \n",
    "        epochs=EPOCHS, \n",
    "        verbose=False,)\n",
    "\n",
    "    # loss = history.history['loss']\n",
    "    # plt.plot(loss)\n",
    "    # plt.xlabel('Epoch')\n",
    "    # plt.ylabel('MSE-Loss')\n",
    "\n",
    "    ae.encoder.save(f'{ENC_FNAME}.h5')\n",
    "    ae.decoder.save(f'{DEC_FNAME}.h5')\n",
    "    return ae\n",
    "\n",
    "def load_ae_model():\n",
    "    encoder = load_model(f'{ENC_FNAME}.h5')\n",
    "    decoder = load_model(f'{DEC_FNAME}.h5')\n",
    "    return AE(encoder=encoder, decoder=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91035836-4c13-489b-a865-bed0817aaeb0",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1371f3be-fafd-45c6-978b-d2c65924d21e",
   "metadata": {},
   "source": [
    "We need a tree-based model to get results for the tree SHAP explainer. Hence we train a random forest on the wine-quality dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07246f62-3040-475e-843e-b0366c3d94fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "def make_rfc():\n",
    "    rfc = RandomForestClassifier(n_estimators=50)\n",
    "    rfc.fit(scaler.transform(X_train), y_train_lab)\n",
    "    y_pred = rfc.predict(scaler.transform(X_test))\n",
    "\n",
    "    print('accuracy_score:', accuracy_score(y_pred, y_test_lab))\n",
    "    print('f1_score:', f1_score(y_test_lab, y_pred, average=None))\n",
    "\n",
    "    joblib.dump(rfc, f\"{RFC_FNAME}.joblib\")\n",
    "    return rfc\n",
    "\n",
    "\n",
    "def load_rfc_model():\n",
    "    return joblib.load(f\"{RFC_FNAME}.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdd201e-2783-42d3-a345-cf742361be67",
   "metadata": {},
   "source": [
    "### Tensorflow Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c29f129-3e75-4fc7-8893-18ab09019ae9",
   "metadata": {},
   "source": [
    "Finally, we also train a TensorFlow model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a28547f-1e0a-4bf4-9f18-5451127ddb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers \n",
    "\n",
    "def make_tf_model():\n",
    "    inputs = keras.Input(shape=X_train.shape[1])\n",
    "    x = layers.Dense(6, activation=\"relu\")(inputs)\n",
    "    outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "    history = model.fit(\n",
    "        scaler.transform(X_train), \n",
    "        y_train,\n",
    "        epochs=30, \n",
    "        verbose=False, \n",
    "        validation_data=(scaler.transform(X_test), y_test),\n",
    "    )\n",
    "\n",
    "    y_pred = model(scaler.transform(X_test)).numpy().argmax(axis=1)\n",
    "    print('accuracy_score:', accuracy_score(y_pred, y_test.argmax(axis=1)))\n",
    "    print('f1_score:', f1_score(y_pred, y_test.argmax(axis=1), average=None))\n",
    "\n",
    "    model.save(f'{TF_MODEL_FNAME}.h5')\n",
    "    return model\n",
    "\n",
    "def load_tf_model():\n",
    "    return load_model(f'{TF_MODEL_FNAME}.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7e779e-656d-48be-91b2-14ae32e2838c",
   "metadata": {},
   "source": [
    "### Load/Make models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faa7413-c589-45ed-9c64-96b8ddbac469",
   "metadata": {},
   "source": [
    "We save and load the same models each time to ensure stable results. If they don't exist we create new ones. If you want to generate new models on each notebook run, then set `FROM_SCRATCH=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dc61ede-5732-4641-b004-0be40fbf9e99",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m     rfc \u001b[38;5;241m=\u001b[39m load_rfc_model()\n\u001b[0;32m----> 7\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mload_tf_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m      8\u001b[0m     ae \u001b[38;5;241m=\u001b[39m load_ae_model()\n",
      "Cell \u001b[0;32mIn[9], line 27\u001b[0m, in \u001b[0;36mload_tf_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_tf_model\u001b[39m():\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model\u001b[49m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTF_MODEL_FNAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "if FROM_SCRATCH or not os.path.isfile(f'{TF_MODEL_FNAME}.h5'):\n",
    "    model = make_tf_model()\n",
    "    rfc = make_rfc()\n",
    "    ae = make_ae()\n",
    "else:\n",
    "    rfc = load_rfc_model()\n",
    "    model = load_tf_model() \n",
    "    ae = load_ae_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a89f7e-7a76-4c9f-b313-ce963227f548",
   "metadata": {},
   "source": [
    "## Util functions\n",
    "\n",
    "These are utility functions for exploring results. The first shows two instances of the data side by side and compares the difference. We'll use this to see how the counterfactuals differ from their original instances. The second function plots the importance of each feature. This will be useful for visualizing the attribution methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231a5665-6dfc-475c-b456-0f25598c319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_instances(x, cf):\n",
    "    \"\"\"\n",
    "    Show the difference in values between two instances.\n",
    "    \"\"\"\n",
    "    x = x.astype('float64')\n",
    "    cf = cf.astype('float64')\n",
    "    for f, v1, v2 in zip(features, x[0], cf[0]):\n",
    "        print(f'{f:<25} instance: {round(v1, 3):^10} counter factual: {round(v2, 3):^10} difference: {round(v1 - v2, 7):^5}')\n",
    "\n",
    "def plot_importance(feat_imp, feat_names, class_idx, **kwargs):\n",
    "    \"\"\"\n",
    "    Create a horizontal barchart of feature effects, sorted by their magnitude.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.DataFrame(data=feat_imp, columns=feat_names).sort_values(by=0, axis='columns')\n",
    "    feat_imp, feat_names = df.values[0], df.columns\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    y_pos = np.arange(len(feat_imp))\n",
    "    ax.barh(y_pos, feat_imp)\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(feat_names, fontsize=15)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel(f'Feature effects for class {class_idx}', fontsize=15)\n",
    "    return ax, fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a723129-19e5-4f87-b1c2-bfec2a4c69b1",
   "metadata": {},
   "source": [
    "## Local Feature Attribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559872af-99b6-4314-b418-0be491f3f405",
   "metadata": {},
   "source": [
    "### Integrated Gradients\n",
    "\n",
    "The integrated gradients (IG) method computes the attribution of each feature by integrating the model partial derivatives along a path from a baseline point to the instance. This accumulates the changes in the prediction that occur due to the changing feature values. These accumulated values represent how each feature contributes to the prediction for the instance of interest.\n",
    "\n",
    "We illustrate the application of IG to the instance of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fb53ef-d965-4bd5-b70c-09badbfbfc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.explainers import IntegratedGradients\n",
    "\n",
    "ig = IntegratedGradients(model,\n",
    "                         layer=None,\n",
    "                         method=\"gausslegendre\",\n",
    "                         n_steps=50,\n",
    "                         internal_batch_size=100)\n",
    "\n",
    "result = ig.explain(scaler.transform(x), target=0)\n",
    "\n",
    "plot_importance(result.data['attributions'][0], features, '\"good\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91775149-0ff9-46d7-a71d-d32c910c2757",
   "metadata": {},
   "source": [
    "### Kernel SHAP\n",
    "\n",
    "Kernel SHAP is a method for computing the Shapley values of a model around an instance. Shapley values are a game-theoretic method of assigning payout to players depending on their contribution to an overall goal. In our case, the features are the players, and the payouts are the attributions.\n",
    "\n",
    "Here we give an example of Kernel SHAP method applied to the Tensorflow model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442a2603-1aed-4cd2-a3dc-f4965f5efaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.explainers import KernelShap\n",
    "\n",
    "predict_fn = lambda x: model(scaler.transform(x))\n",
    "\n",
    "explainer = KernelShap(predict_fn, task='classification')\n",
    "\n",
    "explainer.fit(X_train[0:100])\n",
    "\n",
    "result = explainer.explain(x)\n",
    "\n",
    "plot_importance(result.shap_values[0], features, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a6161f-13b6-4156-b378-bd689e68d00f",
   "metadata": {},
   "source": [
    "Here we apply Kernel SHAP to the Tree-based model to compare to the tree-based methods we run later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77deef77-42c1-4450-b381-fde4b1079e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.explainers import KernelShap\n",
    "\n",
    "predict_fn = lambda x: rfc.predict_proba(scaler.transform(x))\n",
    "\n",
    "explainer = KernelShap(predict_fn, task='classification')\n",
    "\n",
    "explainer.fit(X_train[0:100])\n",
    "\n",
    "result = explainer.explain(x)\n",
    "\n",
    "plot_importance(result.shap_values[1], features, '\"Good\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f0d0aa-f805-4ca7-9d26-4280548dd66b",
   "metadata": {},
   "source": [
    "### Interventional treeSHAP\n",
    "\n",
    "Interventional tree SHAP computes the same Shapley values as the kernel SHAP method above. The difference is that it's much faster for tree-based models. Here it is applied to the random forest we trained. Comparison with the kernel SHAP results above show very similar outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3b1ce0-8d52-4a6f-b30c-40779b9b2a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.explainers import TreeShap\n",
    "\n",
    "tree_explainer_interventional = TreeShap(rfc, model_output='raw', task='classification')\n",
    "tree_explainer_interventional.fit(scaler.transform(X_train[0:100]))\n",
    "result = tree_explainer_interventional.explain(scaler.transform(x), check_additivity=False)\n",
    "\n",
    "plot_importance(result.shap_values[1], features, '\"Good\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c05d4f-13b8-4266-bced-510664ba7342",
   "metadata": {},
   "source": [
    "### Path Dependent treeSHAP\n",
    "\n",
    "Path Dependent tree SHAP gives the same results as the Kernel SHAP method, only faster. Here it is applied to a random forest model. Again very similar results to kernel SHAP and Interventional tree SHAP as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeef4572-2c4e-41ea-8298-80c95476be96",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dependent_explainer = TreeShap(rfc, model_output='raw', task='classification')\n",
    "path_dependent_explainer.fit()\n",
    "result = path_dependent_explainer.explain(scaler.transform(x))\n",
    "\n",
    "plot_importance(result.shap_values[1], features, '\"Good\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ccd4c7-b4b9-4b3b-bf5e-75aeb8653bc7",
   "metadata": {},
   "source": [
    "**Note**: There is some difference between the kernel SHAP and integrated gradient applied to the TensorFlow model and the SHAP methods applied to the random forest. This is expected due to the combination of different methods and models. They are reasonably similar overall. Notably, the ordering is nearly the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecdab93-3226-4b76-a0d0-e01b740b865e",
   "metadata": {},
   "source": [
    "## Local Necessary Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c32759e-e66f-4af9-91af-e5d1deb01019",
   "metadata": {},
   "source": [
    "### Anchors\n",
    "\n",
    "Anchors tell us what features need to stay the same for a specific instance for the model to give the same classification. In the case of a trained image classification model, an anchor for a given instance would be a minimal subset of the image that the model uses to make its decision.\n",
    "\n",
    "Here we apply Anchors to the tensor flow model trained on the wine-quality dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e36d1c9-49e1-4da8-9bc8-da312e2b31b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.explainers import AnchorTabular\n",
    "\n",
    "predict_fn = lambda x: model.predict(scaler.transform(x))\n",
    "explainer = AnchorTabular(predict_fn, features)\n",
    "explainer.fit(X_train, disc_perc=(25, 50, 75))\n",
    "result = explainer.explain(x, threshold=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1600dade-52d0-40b8-a29c-d8279bbb1a94",
   "metadata": {},
   "source": [
    "The result is a set of predicates that tell you whether a point in the data set is in the anchor or not. If it is in the anchor, it is very likely to have the same classification as the instance `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3722d3-f837-4343-a2de-c7f4d4849223",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Anchor =', result.data['anchor'])\n",
    "print('Precision = ', result.data['precision'])\n",
    "print('Coverage = ', result.data['coverage'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a91fed-7171-4dae-abd4-9e8709bb5aa8",
   "metadata": {},
   "source": [
    "## Global Feature Attribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a604116-6772-469d-b251-05fb920f6fb7",
   "metadata": {},
   "source": [
    "### ALE \n",
    "\n",
    "ALE plots show the dependency of model output on a subset of the input features. They provide global insight describing the model's behaviour over the input space. Here we use ALE to directly visualize the relationship between the TensorFlow model's predictions and the alcohol content of wine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3596db3d-40bb-42e4-9b59-1ae18f6be64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.explainers import ALE\n",
    "from alibi.explainers.ale import plot_ale\n",
    "\n",
    "predict_fn = lambda x: model(scaler.transform(x)).numpy()[:, 0]\n",
    "ale = ALE(predict_fn, feature_names=features)\n",
    "exp = ale.explain(X_train)\n",
    "plot_ale(exp, features=['alcohol'], line_kw={'label': 'Probability of \"good\" class'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43934de4-cdb7-497c-9eb4-d83bb1a9a8c6",
   "metadata": {},
   "source": [
    "## Counterfactuals\n",
    "\n",
    "Next, we apply each of the \"counterfactuals with reinforcement learning\", \"counterfactual instances\", \"contrastive explanation method\", and the \"counterfactuals with prototypes\" methods. We also plot the kernel SHAP values to show how the counterfactual methods change the attribution of each feature leading to the change in prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacbe189-a135-4ef9-bcf4-35df9019d5bb",
   "metadata": {},
   "source": [
    "### Counter Factuals with Reinforcement Learning\n",
    "\n",
    "CFRL trains a new model when fitting the explainer called an actor that takes instances and produces counterfactuals. It does this using reinforcement learning. In reinforcement learning, an actor model takes some state as input and generates actions; in our case, the actor takes an instance with a target classification and attempts to produce a member of the target class. Outcomes of actions are assigned rewards dependent on a reward function designed to encourage specific behaviors. In our case, we reward correctly classified counterfactuals generated by the actor. As well as this, we reward counterfactuals that are close to the data distribution as modeled by an autoencoder. Finally, we require that they are sparse perturbations of the original instance. The reinforcement training step pushes the actor to take high reward actions. CFRL is a black-box method as the process by which we update the actor to maximize the reward only requires estimating the reward via sampling the counterfactuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fbd60a-64af-43f9-80d3-9b78cfde8079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.explainers import CounterfactualRL \n",
    "\n",
    "predict_fn = lambda x: model(x)\n",
    "\n",
    "cfrl_explainer = CounterfactualRL(\n",
    "    predictor=predict_fn,               # The model to explain\n",
    "    encoder=ae.encoder,                 # The encoder\n",
    "    decoder=ae.decoder,                 # The decoder\n",
    "    latent_dim=7,                       # The dimension of the autoencoder latent space\n",
    "    coeff_sparsity=0.5,                 # The coefficient of sparsity\n",
    "    coeff_consistency=0.5,              # The coefficient of consistency\n",
    "    train_steps=10000,                  # The number of training steps\n",
    "    batch_size=100,                     # The batch size\n",
    ")\n",
    "\n",
    "cfrl_explainer.fit(X=scaler.transform(X_train))\n",
    "\n",
    "result_cfrl = cfrl_explainer.explain(X=scaler.transform(x), Y_t=np.array([1]))\n",
    "print(\"Instance class prediction:\", model.predict(scaler.transform(x))[0].argmax())\n",
    "print(\"Counterfactual class prediction:\", model.predict(result_cfrl.data['cf']['X'])[0].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6559f2e3-72db-4ca3-b949-8e3d7371a10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfrl = scaler.inverse_transform(result_cfrl.data['cf']['X'])\n",
    "compare_instances(x, cfrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1c7e49-c6dc-41c5-9214-d33f42569231",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.explainers import KernelShap\n",
    "\n",
    "predict_fn = lambda x: model(scaler.transform(x))\n",
    "\n",
    "explainer = KernelShap(predict_fn, task='classification')\n",
    "\n",
    "explainer.fit(X_train[0:100])\n",
    "\n",
    "result_x = explainer.explain(x)\n",
    "result_cfrl = explainer.explain(cfrl)\n",
    "\n",
    "plot_importance(result_x.shap_values[0], features, 0)\n",
    "plot_importance(result_cfrl.shap_values[0], features, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9223ff2e-66c7-40a0-ba8a-7655ef7650ca",
   "metadata": {},
   "source": [
    "### Counterfactual Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d142f8a-c97f-4965-8b76-840b0aed5164",
   "metadata": {},
   "source": [
    "First we need to revert to using tfv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc13edf-3e05-4a7f-b5d6-f822923df98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38105a7b-b86e-4720-9015-e7838ed82e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, load_model\n",
    "model = load_tf_model() \n",
    "ae = load_ae_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d48f384-3c88-4735-84c0-af9b0d76b7bd",
   "metadata": {},
   "source": [
    "The counterfactual instance method in alibi generates counterfactuals by defining a loss that prefers interpretable instances close to the target class. It then uses gradient descent to move within the feature space until it obtains a counterfactual of sufficient quality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cf22f1-0adb-4cfb-b258-aadcab34c46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.explainers import Counterfactual\n",
    "\n",
    "explainer = Counterfactual(\n",
    "    model,                              # The model to explain\n",
    "    shape=(1,) + X_train.shape[1:],     # The shape of the model input\n",
    "    target_proba=0.51,                  # The target class probability\n",
    "    tol=0.01,                           # The tolerance for the loss\n",
    "    target_class='other',               # The target class to obtain  \n",
    ")\n",
    "\n",
    "result_cf = explainer.explain(scaler.transform(x))\n",
    "print(\"Instance class prediction:\", model.predict(scaler.transform(x))[0].argmax())\n",
    "print(\"Counterfactual class prediction:\", model.predict(result_cf.data['cf']['X'])[0].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a4399b-659c-4d60-bd2c-e3c6ca259f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = scaler.inverse_transform(result_cf.data['cf']['X'])\n",
    "compare_instances(x, cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7becb3-3006-468a-9b98-1ebd02dc7288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.explainers import KernelShap\n",
    "\n",
    "predict_fn = lambda x: model.predict(scaler.transform(x))\n",
    "\n",
    "explainer = KernelShap(predict_fn, task='classification')\n",
    "\n",
    "explainer.fit(X_train[0:100])\n",
    "\n",
    "result_x = explainer.explain(x)\n",
    "result_cf = explainer.explain(cf)\n",
    "\n",
    "plot_importance(result_x.shap_values[0], features, 0)\n",
    "plot_importance(result_cf.shap_values[0], features, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ad53ba-d63e-4edc-b9d0-bc4ba305a593",
   "metadata": {},
   "source": [
    "### Contrastive Explanations Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5db134-dd36-44c1-9b19-b04dddd66a2b",
   "metadata": {},
   "source": [
    "The CEM method generates counterfactuals by defining a loss that prefers interpretable instances close to the target class. It also adds an autoencoder reconstruction loss to ensure the counterfactual stays within the data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa6351b-01fd-4f6b-8f05-92f187b2737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.explainers import CEM\n",
    "\n",
    "cem = CEM(model,                            # model to explain\n",
    "          shape=(1,) + X_train.shape[1:],   # shape of the model input\n",
    "          mode='PN',                        # pertinant negative mode\n",
    "          kappa=0.2,                        # Confidence parameter for the attack loss term\n",
    "          beta=0.1,                         # Regularization constant for L1 loss term\n",
    "          ae_model=ae                       # autoencoder model\n",
    ")\n",
    "\n",
    "cem.fit(\n",
    "    scaler.transform(X_train), # scaled training data\n",
    "    no_info_type='median'      # non-informative value for each feature\n",
    ")\n",
    "result_cem = cem.explain(scaler.transform(x), verbose=False)\n",
    "cem_cf = result_cem.data['PN']\n",
    "\n",
    "print(\"Instance class prediction:\", model.predict(scaler.transform(x))[0].argmax())\n",
    "print(\"Counterfactual class prediction:\", model.predict(cem_cf)[0].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96abe72c-2e01-402d-b2ed-9b61f208a95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cem_cf = result_cem.data['PN']\n",
    "cem_cf = scaler.inverse_transform(cem_cf)\n",
    "compare_instances(x, cem_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298651d6-de8b-405e-a174-a207df37ffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.explainers import KernelShap\n",
    "\n",
    "predict_fn = lambda x: model.predict(scaler.transform(x))\n",
    "\n",
    "explainer = KernelShap(predict_fn, task='classification')\n",
    "\n",
    "explainer.fit(X_train[0:100])\n",
    "\n",
    "result_x = explainer.explain(x)\n",
    "result_cem_cf = explainer.explain(cem_cf)\n",
    "\n",
    "plot_importance(result_x.shap_values[0], features, 0)\n",
    "plot_importance(result_cem_cf.shap_values[0], features, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f58f8b-944a-4a5d-8d74-fc2fce4b0f6d",
   "metadata": {},
   "source": [
    "### Counterfactual With Prototypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8777b84e-7bc6-47ca-be2b-10943084103f",
   "metadata": {},
   "source": [
    "Like the previous two methods, \"counterfactuals with prototypes\" defines a loss that guides the counterfactual towards the target class while also using an autoencoder to ensure it stays within the data distribution. As well as this, it uses prototype instances of the target class to ensure that the generated counterfactual is interpretable as a member of the target class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a63b6f-58a1-4fc0-9aa6-528507158eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.explainers import CounterfactualProto\n",
    "\n",
    "explainer = CounterfactualProto(\n",
    "    model,                           # The model to explain\n",
    "    shape=(1,) + X_train.shape[1:],  # shape of the model input\n",
    "    ae_model=ae,                     # The autoencoder\n",
    "    enc_model=ae.encoder             # The encoder\n",
    ")\n",
    "\n",
    "explainer.fit(scaler.transform(X_train)) # Fit the explainer with scaled data\n",
    "\n",
    "result_proto = explainer.explain(scaler.transform(x), verbose=False)\n",
    "\n",
    "proto_cf = result_proto.data['cf']['X']\n",
    "print(\"Instance class prediction:\", model.predict(scaler.transform(x))[0].argmax())\n",
    "print(\"Counterfactual class prediction:\", model.predict(proto_cf)[0].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6116d6-b739-436c-8179-1cbaddf218c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "proto_cf = scaler.inverse_transform(proto_cf)\n",
    "compare_instances(x, proto_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1e5206-cca6-4897-a486-8a4bf070e93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.explainers import KernelShap\n",
    "\n",
    "predict_fn = lambda x: model.predict(scaler.transform(x))\n",
    "\n",
    "explainer = KernelShap(predict_fn, task='classification')\n",
    "\n",
    "explainer.fit(X_train[0:100])\n",
    "\n",
    "result_x = explainer.explain(x)\n",
    "result_proto_cf = explainer.explain(cem_cf)\n",
    "\n",
    "plot_importance(result_x.shap_values[0], features, 0)\n",
    "print(result_x.shap_values[0].sum())\n",
    "plot_importance(result_proto_cf.shap_values[0], features, 0)\n",
    "print(result_proto_cf.shap_values[0].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f4ccc1-d2ef-4623-a8b8-dae2518c3d26",
   "metadata": {},
   "source": [
    "Looking at the ALE plots below, we can see how the counterfactual methods change the features to flip the prediction. Note that the ALE plots potentially miss details local to individual instances as they are global insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c990ef-808f-4502-9806-6d03c6635a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ale(exp, features=['sulphates', 'alcohol', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide'], line_kw={'label': 'Probability of \"good\" class'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
