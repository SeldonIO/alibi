{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "%set_env CUDA_VISIBLE_DEVICES=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import DistilBertTokenizerFast, TFBertModel, BertConfig\n",
    "from alibi.explainers import IntegratedGradients\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_reviews(reviews):\n",
    "    \n",
    "    REPLACE_NO_SPACE = re.compile(\"[.;:,!\\'?\\\"()\\[\\]]\")\n",
    "    REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "    \n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "def process_sentences(sentence1, \n",
    "                      tokenizer, \n",
    "                      max_len, \n",
    "                      add_special_tokens=True):\n",
    "\n",
    "    z = tokenizer(sentence1, \n",
    "                  add_special_tokens = add_special_tokens, \n",
    "                  padding = 'max_length', \n",
    "                  max_length = max_len, truncation = True,\n",
    "                  return_token_type_ids=True, \n",
    "                  return_attention_mask = True,  \n",
    "                  return_tensors = 'np')\n",
    "\n",
    "    return [z['input_ids'], z['attention_mask']]\n",
    "\n",
    "def decode_sentence(x, reverse_index):\n",
    "    # the `-3` offset is due to the special tokens used by keras\n",
    "    # see https://stackoverflow.com/questions/42821330/restore-original-text-from-keras-s-imdb-dataset\n",
    "    return \" \".join([reverse_index.get(i - 3, 'UNK') for i in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load imdb dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "max_len = 100\n",
    "add_special_tokens=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "test_labels = y_test.copy()\n",
    "train_labels = y_train.copy()\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "index = imdb.get_word_index()\n",
    "reverse_index = {value: key for (key, value) in index.items()} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session, we will use the tensorflow auto model for sequence classification. This model is already finetuned for sentiment analisys and do not require training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "auto_model_bert = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The automodel output is a custom object containing the output logits. We use a wrapper to transform this output in a tensor and apply a softmax function on the logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoModelWrapper(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, model_bert, **kwargs):\n",
    "        super(AutoModelWrapper, self).__init__()\n",
    "        self.model_bert = model_bert\n",
    "\n",
    "    def call(self, inputs, attention_mask=None, output_nb=5):\n",
    "        out = self.model_bert(inputs, attention_mask=attention_mask)\n",
    "        return tf.nn.softmax(out.logits)\n",
    "        #return out\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {}\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozenModelOut = AutoModelWrapper(auto_model_bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate ingrated gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we calculate the integrated gradients for the first 10 reviews in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_test_sample = [\"I love you, I like you\",\n",
    "#                \"I love you, I like you, I also kinda dislike you\",\n",
    "#                \"I hate you, I dislike you, but maybe not\"]\n",
    "x_test_sample = [decode_sentence(x_test[i], reverse_index) for i in range(10)]\n",
    "x_test_sample = preprocess_reviews(x_test_sample)\n",
    "x_test_sample = process_sentences(x_test_sample, \n",
    "                                   tokenizer, \n",
    "                                   max_len,\n",
    "                                   add_special_tokens=add_special_tokens)\n",
    "kwargs = {'attention_mask': x_test_sample[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\n",
       "array([[9.9760783e-01, 2.3921041e-03],\n",
       "       [5.7495857e-04, 9.9942505e-01],\n",
       "       [3.7964460e-02, 9.6203548e-01],\n",
       "       [9.9770999e-01, 2.2900314e-03],\n",
       "       [3.7964175e-03, 9.9620360e-01],\n",
       "       [9.9792743e-01, 2.0725005e-03],\n",
       "       [9.0457928e-01, 9.5420703e-02],\n",
       "       [9.9938536e-01, 6.1466231e-04],\n",
       "       [9.2592180e-01, 7.4078158e-02],\n",
       "       [1.7677458e-03, 9.9823231e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_out = frozenModelOut(x_test_sample[0], **kwargs)\n",
    "auto_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing which to which embeddings block we want to calculate the attributions for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.models.distilbert.modeling_tf_distilbert.TFTransformerBlock at 0x7f957d19c3d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bl = frozenModelOut.layers[0].layers[0].transformer.layer[1]\n",
    "bl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 5\n",
    "method = \"gausslegendre\"\n",
    "internal_batch_size = 5\n",
    "ig  = IntegratedGradients(frozenModelOut,\n",
    "                          layer=bl,\n",
    "                          n_steps=n_steps, \n",
    "                          method=method,\n",
    "                          internal_batch_size=internal_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f97648b7670>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f97648b7670>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:From /home/gio/anaconda3/envs/intgrads/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    }
   ],
   "source": [
    "predictions = frozenModelOut(x_test_sample[0], **kwargs).numpy().argmax(axis=1)\n",
    "explanation = ig.explain(x_test_sample[0], \n",
    "                         forward_kwargs=kwargs,\n",
    "                         baselines=None, \n",
    "                         target=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributions shape: (10, 100, 768)\n"
     ]
    }
   ],
   "source": [
    "# Get attributions values from the explanation object\n",
    "attrs = explanation.attributions[0]\n",
    "print('Attributions shape:', attrs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributions shape: (10, 100)\n"
     ]
    }
   ],
   "source": [
    "attrs = attrs.sum(axis=2)\n",
    "print('Attributions shape:', attrs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "x_i = x_test_sample[0][i]\n",
    "attrs_i = attrs[i]\n",
    "pred = predictions[i]\n",
    "pred_dict = {1: 'Positive review', 0: 'Negative review'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "def  hlstr(string, color='white'):\n",
    "    \"\"\"\n",
    "    Return HTML markup highlighting text with the desired color.\n",
    "    \"\"\"\n",
    "    return f\"<mark style=background-color:{color}>{string} </mark>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorize(attrs, cmap='PiYG'):\n",
    "    \"\"\"\n",
    "    Compute hex colors based on the attributions for a single instance.\n",
    "    Uses a diverging colorscale by default and normalizes and scales\n",
    "    the colormap so that colors are consistent with the attributions.\n",
    "    \"\"\"\n",
    "    import matplotlib as mpl\n",
    "    cmap_bound = np.abs(attrs).max()\n",
    "    norm = mpl.colors.Normalize(vmin=-cmap_bound, vmax=cmap_bound)\n",
    "    cmap = mpl.cm.get_cmap(cmap)\n",
    "    \n",
    "    # now compute hex values of colors\n",
    "    colors = list(map(lambda x: mpl.colors.rgb2hex(cmap(norm(x))), attrs))\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = tokenizer.decode(x_i).split()\n",
    "colors = colorize(attrs_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label =  1: Positive review\n"
     ]
    }
   ],
   "source": [
    "print('Predicted label =  {}: {}'.format(pred, pred_dict[pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<mark style=background-color:#e9f5d6>a </mark><mark style=background-color:#276419>powerful </mark><mark style=background-color:#d4edb3>study </mark><mark style=background-color:#f5f7f2>of </mark><mark style=background-color:#f9eef4>loneliness </mark><mark style=background-color:#f1f6ea>sexual </mark><mark style=background-color:#f9f0f5>unk </mark><mark style=background-color:#f6f7f5>and </mark><mark style=background-color:#f1f6e8>desperation </mark><mark style=background-color:#f3f7ef>be </mark><mark style=background-color:#f7f7f7>patient </mark><mark style=background-color:#f4f7f0>unk </mark><mark style=background-color:#f7f7f6>up </mark><mark style=background-color:#f5f7f3>the </mark><mark style=background-color:#fbe8f2>atmosphere </mark><mark style=background-color:#f5f7f3>and </mark><mark style=background-color:#f4f7f0>pay </mark><mark style=background-color:#f8f4f6>attention </mark><mark style=background-color:#fde0ef>to </mark><mark style=background-color:#f0f6e7>the </mark><mark style=background-color:#edf6e1>wonderfully </mark><mark style=background-color:#e8f5d5>written </mark><mark style=background-color:#7dba40>script </mark><mark style=background-color:#f0f6e7>br </mark><mark style=background-color:#f4f7f0>br </mark><mark style=background-color:#f8f4f6>i </mark><mark style=background-color:#fcdded>praise </mark><mark style=background-color:#fde1ef>robert </mark><mark style=background-color:#f3f7ef>altman </mark><mark style=background-color:#bee490>this </mark><mark style=background-color:#c2e596>is </mark><mark style=background-color:#d8efb9>one </mark><mark style=background-color:#d2ecb0>of </mark><mark style=background-color:#f0f6e7>his </mark><mark style=background-color:#91c857>many </mark><mark style=background-color:#7fbc41>films </mark><mark style=background-color:#b5df82>that </mark><mark style=background-color:#9ed067>deals </mark><mark style=background-color:#91c857>with </mark><mark style=background-color:#83bf46>unconventional </mark><mark style=background-color:#5a9d29>fascinating </mark><mark style=background-color:#c0e593>subject </mark><mark style=background-color:#e8f5d5>matter </mark><mark style=background-color:#acd977>this </mark><mark style=background-color:#c9e8a2>film </mark><mark style=background-color:#f8f5f6>is </mark><mark style=background-color:#f4f7f0>disturbing </mark><mark style=background-color:#eff6e5>but </mark><mark style=background-color:#eff6e5>its </mark><mark style=background-color:#faeaf2>sincere </mark><mark style=background-color:#f3f6ed>and </mark><mark style=background-color:#f8f5f6>its </mark><mark style=background-color:#f1f6ea>sure </mark><mark style=background-color:#b0dc7d>to </mark><mark style=background-color:#f1f6e8>unk </mark><mark style=background-color:#f2f6ec>a </mark><mark style=background-color:#f9f1f5>strong </mark><mark style=background-color:#f7f6f7>emotional </mark><mark style=background-color:#fbe8f2>response </mark><mark style=background-color:#faeaf2>from </mark><mark style=background-color:#f4f7f0>the </mark><mark style=background-color:#468a20>viewer </mark><mark style=background-color:#cdeaa7>if </mark><mark style=background-color:#d2ecb0>you </mark><mark style=background-color:#ebf6dc>want </mark><mark style=background-color:#f2f6ec>to </mark><mark style=background-color:#e9f5d6>see </mark><mark style=background-color:#f3f7ef>an </mark><mark style=background-color:#f0f6e7>unusual </mark><mark style=background-color:#f7f6f7>film </mark><mark style=background-color:#f5f7f2>some </mark><mark style=background-color:#f3f7ef>might </mark><mark style=background-color:#f1f6e8>even </mark><mark style=background-color:#e9f5d8>say </mark><mark style=background-color:#ebf6db>bizarre </mark><mark style=background-color:#f1f6ea>this </mark><mark style=background-color:#f7f7f6>is </mark><mark style=background-color:#f2f6ec>worth </mark><mark style=background-color:#eff6e4>the </mark><mark style=background-color:#eff6e5>time </mark><mark style=background-color:#eff6e4>br </mark><mark style=background-color:#f0f6e7>br </mark><mark style=background-color:#f4f7f0>unfortunately </mark><mark style=background-color:#f5f7f2>its </mark><mark style=background-color:#f4f7f0>very </mark><mark style=background-color:#fcdded>difficult </mark><mark style=background-color:#fddeee>to </mark><mark style=background-color:#f9f1f5>find </mark><mark style=background-color:#eff6e5>in </mark><mark style=background-color:#f9f1f5>video </mark><mark style=background-color:#fde2f0>stores </mark><mark style=background-color:#f9eef4>you </mark><mark style=background-color:#faeaf2>may </mark><mark style=background-color:#f9f0f5>have </mark><mark style=background-color:#f7f6f7>to </mark>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\".join(list(map(hlstr, words, colors))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune bert with custom model's head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session we use a pretrained bert model combined with a custom model's head. We fine tune the model's head for sentiment analysis on the imdb dataset. The bert model is used to produced embeddings, which are then used as input features for a simple feed forward network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator():\n",
    "    for s1, s2, l in zip(X_train[0], X_train[1], y_train):\n",
    "        yield {'input_ids': s1, 'attention_mask': s2}, l\n",
    "        \n",
    "def test_generator():\n",
    "    for s1, s2, l in zip(X_test[0], X_test[1], y_test):\n",
    "        yield {'input_ids': s1, 'attention_mask': s2}, l\n",
    "\n",
    "def get_embeddings(generator, model, batch_size=50, stop_after_batch=2):\n",
    "    dataset = tf.data.Dataset.from_generator(generator,\n",
    "                                             output_types=({'input_ids': tf.int64,\n",
    "                                                              'attention_mask': tf.int64}, \n",
    "                                                             tf.int64))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    embbedings = []\n",
    "\n",
    "    i = 0\n",
    "    for X_batch in dataset:\n",
    "        batch_embeddings = model(X_batch[0])\n",
    "        embbedings.append(batch_embeddings.last_hidden_state.numpy())\n",
    "        \n",
    "        i += 1\n",
    "        # Stopping the extraction after 3 batches for code testing,\n",
    "        # since extracting embeddings for the whole dataset is slow.\n",
    "        if stop_after_batch is not None:\n",
    "            if i > stop_after_batch: \n",
    "                break\n",
    "\n",
    "    return np.concatenate(embbedings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "config = BertConfig.from_pretrained(\"bert-base-uncased\", \n",
    "                                    output_hidden_states=True)\n",
    "modelBert = TFBertModel.from_pretrained(\"bert-base-uncased\",\n",
    "                                        config=config)\n",
    "\n",
    "modelBert.trainable=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract embeddings for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE (to delete): Here we extract the embedding for training. Extracting the embedding for the whole dataset is very slow. For the sake of testing the code, here the extraction is stopped after 3 batches of 50 sentences. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_emb = 50\n",
    "stop_after_batch = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = [], []\n",
    "for i in range(len(x_train)):\n",
    "    tr_sentence = decode_sentence(x_train[i], reverse_index)\n",
    "    X_train.append(tr_sentence)\n",
    "    te_sentence = decode_sentence(x_test[i], reverse_index)\n",
    "    X_test.append(te_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocess_reviews(X_train)\n",
    "X_train = process_sentences(X_train, \n",
    "                           tokenizer, \n",
    "                           max_len, \n",
    "                           add_special_tokens=add_special_tokens)\n",
    "X_test = preprocess_reviews(X_test)\n",
    "X_test = process_sentences(X_test,\n",
    "                           tokenizer, \n",
    "                           max_len,\n",
    "                           add_special_tokens=add_special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embbedings = get_embeddings(train_generator, \n",
    "                                  modelBert, \n",
    "                                  batch_size=batch_size_emb, \n",
    "                                  stop_after_batch = stop_after_batch)\n",
    "test_embbedings = get_embeddings(test_generator, \n",
    "                                 modelBert, \n",
    "                                 batch_size=batch_size_emb, \n",
    "                                 stop_after_batch = stop_after_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 100, 768)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embbedings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 100, 768)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_embbedings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = False\n",
    "save_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_filters=64\n",
    "dropout_1=0.4\n",
    "dropout_2=0.\n",
    "hidden_dims=128\n",
    "batch_size = 128\n",
    "epochs = 3\n",
    "skip_conv=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelOut(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, \n",
    "                 nb_filters=32,\n",
    "                 dropout_1=0.2,\n",
    "                 dropout_2=0.2, \n",
    "                 hidden_dims=32,\n",
    "                skip_conv=False):\n",
    "        super(ModelOut, self).__init__()\n",
    "        \n",
    "        self.nb_filters = nb_filters\n",
    "        self.dropout_1 = dropout_1\n",
    "        self.dropout_2 = dropout_2\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.skip_conv = skip_conv\n",
    "        \n",
    "        if not self.skip_conv:\n",
    "            self.conv = tf.keras.layers.Conv1D(nb_filters, \n",
    "                                               kernel_size=3, \n",
    "                                               padding=\"valid\", \n",
    "                                               strides=1)\n",
    "            #self.dropoutl_1 = tf.keras.layers.Dropout(dropout_1)\n",
    "            self.maxpool = tf.keras.layers.GlobalMaxPool1D()\n",
    "        else:\n",
    "            self.flat = tf.keras.layers.Flatten()\n",
    "            \n",
    "        self.dense_1 =  tf.keras.layers.Dense(hidden_dims, \n",
    "                                              activation='relu')\n",
    "        #self.dropoutl_2 = tf.keras.layers.Dropout(dropout_2)\n",
    "        self.dense_2 = tf.keras.layers.Dense(2, \n",
    "                                             activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if not self.skip_conv:\n",
    "            x = self.conv(inputs)\n",
    "            #x = self.dropoutl_1(x)\n",
    "            x = self.maxpool(x)\n",
    "        else:\n",
    "            x = self.flat(inputs)\n",
    "            \n",
    "        x = self.dense_1(x)\n",
    "        #x = self.dropoutl_2(x)\n",
    "        x = self.dense_2(x)\n",
    "        return x\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {\"nb_filters\": self.nb_filters,\n",
    "                \"dropout_1\": self.dropout_1,\n",
    "                \"dropout_2\": self.dropout_2, \n",
    "                \"hidden_dims\": self.hidden_dims,\n",
    "               \"skip_conv\": self.skip_conv}\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out = ModelOut(nb_filters=nb_filters,\n",
    "                 dropout_1=dropout_1,\n",
    "                 dropout_2=dropout_2, \n",
    "                 hidden_dims=hidden_dims,\n",
    "                    skip_conv=skip_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size * (stop_after_batch + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2/2 [==============================] - 1s 343ms/step - loss: 0.9544 - accuracy: 0.4333 - val_loss: 1.1047 - val_accuracy: 0.5133\n",
      "Epoch 2/3\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.8274 - accuracy: 0.5867 - val_loss: 0.8022 - val_accuracy: 0.4867\n",
      "Epoch 3/3\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.8234 - accuracy: 0.4267 - val_loss: 0.8248 - val_accuracy: 0.4867\n"
     ]
    }
   ],
   "source": [
    "filepath = './model_imdb_transformers/'  # change to directory where model is downloaded\n",
    "\n",
    "model_out.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "if not load_model:\n",
    "    \n",
    "    checkpoint_path = os.path.join(filepath, \"training_2/cp-{epoch:04d}.ckpt\")\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "    # Create a callback that saves the model's weights every 5 epochs\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path, \n",
    "        verbose=1, \n",
    "        save_weights_only=True,\n",
    "        save_freq=batch_size)\n",
    "\n",
    "    model_out.fit(train_embbedings, y_train[:batch_size_emb * (stop_after_batch + 1)], \n",
    "                  validation_data=(test_embbedings, y_test[:batch_size_emb * (stop_after_batch + 1)]),\n",
    "                  epochs=epochs, \n",
    "                  batch_size=batch_size,\n",
    "                  callbacks=[cp_callback],\n",
    "                  verbose=1)\n",
    "else:\n",
    "    #model_out.save(filepath)\n",
    "    epoch = 6\n",
    "    load_path = os.path.join(filepath, f\"training_2/cp-{epoch:04d}.ckpt\")\n",
    "    model_out.load_weights(load_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine bert and over head model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class frozenModelOut(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, model_bert, model_out, **kwargs):\n",
    "        super(frozenModelOut, self).__init__()\n",
    "        self.model_bert = model_bert\n",
    "        self.model_out = model_out\n",
    "\n",
    "    def call(self, inputs, attention_mask=None, output_nb=5):\n",
    "        out = self.model_bert(inputs, attention_mask=attention_mask)\n",
    "        out = self.model_out(out.last_hidden_state)\n",
    "        #return tf.nn.softmax(out.logits)\n",
    "        return out\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {}\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozenModelOut = frozenModelOut(modelBert, model_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate ingrated gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_test_sample = [\"I love you, I like you\",\n",
    "#                \"I love you, I like you, I also kinda dislike you\",\n",
    "#                \"I hate you, I dislike you, but maybe not\"]\n",
    "x_test_sample = [decode_sentence(x_test[i], reverse_index) for i in range(10)]\n",
    "x_test_sample = preprocess_reviews(x_test_sample)\n",
    "x_test_sample = process_sentences(x_test_sample, \n",
    "                                   tokenizer, \n",
    "                                   max_len,\n",
    "                                   add_special_tokens=add_special_tokens)\n",
    "kwargs = {'attention_mask': x_test_sample[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\n",
       "array([[0.18093975, 0.81906027],\n",
       "       [0.20847648, 0.7915235 ],\n",
       "       [0.20010987, 0.79989016],\n",
       "       [0.28533247, 0.7146675 ],\n",
       "       [0.23448864, 0.76551133],\n",
       "       [0.26529413, 0.7347058 ],\n",
       "       [0.1632935 , 0.8367065 ],\n",
       "       [0.19886269, 0.8011373 ],\n",
       "       [0.17282802, 0.8271719 ],\n",
       "       [0.20253125, 0.7974687 ]], dtype=float32)>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = frozenModelOut(x_test_sample[0], **kwargs)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.models.bert.modeling_tf_bert.TFBertLayer at 0x7f9530125250>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bl = frozenModelOut.layers[0].bert.encoder.layer[0]\n",
    "bl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 5\n",
    "method = \"gausslegendre\"\n",
    "internal_batch_size = 5\n",
    "ig  = IntegratedGradients(frozenModelOut,\n",
    "                          layer=bl,\n",
    "                          n_steps=n_steps, \n",
    "                          method=method,\n",
    "                          internal_batch_size=internal_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "predictions = frozenModelOut(x_test_sample[0], **kwargs).numpy().argmax(axis=1)\n",
    "explanation = ig.explain(x_test_sample[0], \n",
    "                         forward_kwargs=kwargs,\n",
    "                         baselines=None, \n",
    "                         target=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributions shape: (10, 100, 768)\n"
     ]
    }
   ],
   "source": [
    "# Get attributions values from the explanation object\n",
    "attrs = explanation.attributions[0]\n",
    "print('Attributions shape:', attrs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributions shape: (10, 100)\n"
     ]
    }
   ],
   "source": [
    "attrs = attrs.sum(axis=2)\n",
    "print('Attributions shape:', attrs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "x_i = x_test_sample[0][i]\n",
    "attrs_i = attrs[i]\n",
    "pred = predictions[i]\n",
    "pred_dict = {1: 'Positive review', 0: 'Negative review'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "def  hlstr(string, color='white'):\n",
    "    \"\"\"\n",
    "    Return HTML markup highlighting text with the desired color.\n",
    "    \"\"\"\n",
    "    return f\"<mark style=background-color:{color}>{string} </mark>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorize(attrs, cmap='PiYG'):\n",
    "    \"\"\"\n",
    "    Compute hex colors based on the attributions for a single instance.\n",
    "    Uses a diverging colorscale by default and normalizes and scales\n",
    "    the colormap so that colors are consistent with the attributions.\n",
    "    \"\"\"\n",
    "    import matplotlib as mpl\n",
    "    cmap_bound = np.abs(attrs).max()\n",
    "    norm = mpl.colors.Normalize(vmin=-cmap_bound, vmax=cmap_bound)\n",
    "    cmap = mpl.cm.get_cmap(cmap)\n",
    "    \n",
    "    # now compute hex values of colors\n",
    "    colors = list(map(lambda x: mpl.colors.rgb2hex(cmap(norm(x))), attrs))\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = tokenizer.decode(x_i).split()\n",
    "colors = colorize(attrs_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label =  1: Positive review\n"
     ]
    }
   ],
   "source": [
    "print('Predicted label =  {}: {}'.format(pred, pred_dict[pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<mark style=background-color:#8e0152>a </mark><mark style=background-color:#f9eef4>powerful </mark><mark style=background-color:#f7f7f7>study </mark><mark style=background-color:#f7f7f7>of </mark><mark style=background-color:#f0f6e7>loneliness </mark><mark style=background-color:#dbf0bf>sexual </mark><mark style=background-color:#fbe7f2>unk </mark><mark style=background-color:#e2f3ca>and </mark><mark style=background-color:#fad6ea>desperation </mark><mark style=background-color:#e6f5d0>be </mark><mark style=background-color:#fbe9f2>patient </mark><mark style=background-color:#ecf6de>unk </mark><mark style=background-color:#c2e596>up </mark><mark style=background-color:#d4edb3>the </mark><mark style=background-color:#c2e596>atmosphere </mark><mark style=background-color:#31711b>and </mark><mark style=background-color:#ecf6de>pay </mark><mark style=background-color:#e1f3c7>attention </mark><mark style=background-color:#cdeaa7>to </mark><mark style=background-color:#bee490>the </mark><mark style=background-color:#eef6e2>wonderfully </mark><mark style=background-color:#a1d26a>written </mark><mark style=background-color:#e6f5d0>script </mark><mark style=background-color:#e9f5d6>br </mark><mark style=background-color:#e9f5d6>br </mark><mark style=background-color:#fce5f1>i </mark><mark style=background-color:#ecf6de>praise </mark><mark style=background-color:#fde2f0>robert </mark><mark style=background-color:#f8f2f5>altman </mark><mark style=background-color:#f7f7f7>this </mark><mark style=background-color:#f0f6e7>is </mark><mark style=background-color:#cfebaa>one </mark><mark style=background-color:#fbe8f2>of </mark><mark style=background-color:#dff2c4>his </mark><mark style=background-color:#fce5f1>many </mark><mark style=background-color:#f0f6e7>films </mark><mark style=background-color:#e7f5d2>that </mark><mark style=background-color:#f4f7f0>deals </mark><mark style=background-color:#f9eef4>with </mark><mark style=background-color:#f8f2f5>unconventional </mark><mark style=background-color:#e9f5d8>fascinating </mark><mark style=background-color:#c9e8a2>subject </mark><mark style=background-color:#f8f4f6>matter </mark><mark style=background-color:#edf6e1>this </mark><mark style=background-color:#cdeaa7>film </mark><mark style=background-color:#d4edb3>is </mark><mark style=background-color:#ebf6db>disturbing </mark><mark style=background-color:#83bf46>but </mark><mark style=background-color:#d9f0bc>its </mark><mark style=background-color:#edf6df>sincere </mark><mark style=background-color:#f3f6ed>and </mark><mark style=background-color:#d2ecb0>its </mark><mark style=background-color:#f9f0f5>sure </mark><mark style=background-color:#e8f5d5>to </mark><mark style=background-color:#f1f6ea>unk </mark><mark style=background-color:#f1f6e8>a </mark><mark style=background-color:#eff6e5>strong </mark><mark style=background-color:#f9eef4>emotional </mark><mark style=background-color:#ecf6de>response </mark><mark style=background-color:#eaf5d9>from </mark><mark style=background-color:#d6eeb6>the </mark><mark style=background-color:#f2f6ec>viewer </mark><mark style=background-color:#e8f5d5>if </mark><mark style=background-color:#f0f6e7>you </mark><mark style=background-color:#f3f7ef>want </mark><mark style=background-color:#f7f6f7>to </mark><mark style=background-color:#e8f5d5>see </mark><mark style=background-color:#f4f7f0>an </mark><mark style=background-color:#eaf5d9>unusual </mark><mark style=background-color:#f1f6e8>film </mark><mark style=background-color:#f6f7f5>some </mark><mark style=background-color:#f9eff4>might </mark><mark style=background-color:#f5f7f2>even </mark><mark style=background-color:#faedf3>say </mark><mark style=background-color:#f9eef4>bizarre </mark><mark style=background-color:#f8cee6>this </mark><mark style=background-color:#d9f0bc>is </mark><mark style=background-color:#f9d1e8>worth </mark><mark style=background-color:#f2f6ec>the </mark><mark style=background-color:#fad4e9>time </mark><mark style=background-color:#fbe6f1>br </mark><mark style=background-color:#f7f7f6>br </mark><mark style=background-color:#eff6e5>unfortunately </mark><mark style=background-color:#dd73ac>its </mark><mark style=background-color:#f7f6f7>very </mark><mark style=background-color:#fde1ef>difficult </mark><mark style=background-color:#f2f6ec>to </mark><mark style=background-color:#fddeee>find </mark><mark style=background-color:#f8f2f5>in </mark><mark style=background-color:#f7f6f7>video </mark><mark style=background-color:#f9eff4>stores </mark><mark style=background-color:#f8f2f5>you </mark><mark style=background-color:#e2f3ca>may </mark><mark style=background-color:#c6e79c>have </mark><mark style=background-color:#e9f5d8>to </mark>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\".join(list(map(hlstr, words, colors))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:intgrads] *",
   "language": "python",
   "name": "conda-env-intgrads-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
