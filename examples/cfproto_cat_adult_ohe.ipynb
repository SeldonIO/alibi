{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counterfactual explanations with one-hot encoded categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real world machine learning applications often handle data with categorical variables. Explanation methods which rely on perturbations of the input features need to make sure those perturbations are meaningful and capture the underlying structure of the data. This becomes tricky for categorical features. For instance random perturbations across possible categories or enforcing a ranking between categories based on frequency of occurrence in the training data do not capture this structure. Our method captures the relation between categories of a variable numerically through the context given by the other features in the data and/or the predictions made by the model. First it captures the pairwise distances between categories and then applies multi-dimensional scaling. More details about the method can be found in the [documentation](../doc/source/methods/CFProto.ipynb). The example notebook illustrates this approach on the *adult* dataset, which contains a mixture of categorical and numerical features used to predict whether a person's income is above or below $50k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version:  2.2.0\n",
      "Eager execution enabled:  False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel(40) # suppress deprecation messages\n",
    "tf.compat.v1.disable_v2_behavior() # disable TF2 behaviour as alibi code still relies on TF1 constructs\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from time import time\n",
    "from alibi.datasets import fetch_adult\n",
    "from alibi.explainers import CounterFactualProto\n",
    "from alibi.utils.mapping import ohe_to_ord, ord_to_ohe\n",
    "\n",
    "print('TF version: ', tf.__version__)\n",
    "print('Eager execution enabled: ', tf.executing_eagerly()) # False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load adult dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fetch_adult` function returns a `Bunch` object containing the features, the targets, the feature names and a mapping of the categories in each categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult = fetch_adult()\n",
    "data = adult.data\n",
    "target = adult.target\n",
    "feature_names = adult.feature_names\n",
    "category_map_tmp = adult.category_map\n",
    "target_names = adult.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define shuffled training and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(s=0):\n",
    "    np.random.seed(s)\n",
    "    tf.random.set_seed(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "data_perm = np.random.permutation(np.c_[data, target])\n",
    "X = data_perm[:,:-1]\n",
    "y = data_perm[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 30000\n",
    "y_train, y_test = y[:idx], y[idx+1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorganize data so categorical features come first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.c_[X[:, 1:8], X[:, 11], X[:, 0], X[:, 8:11]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust `feature_names` and `category_map` as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Workclass', 'Education', 'Marital Status', 'Occupation', 'Relationship', 'Race', 'Sex', 'Country', 'Age', 'Capital Gain', 'Capital Loss', 'Hours per week']\n"
     ]
    }
   ],
   "source": [
    "feature_names = feature_names[1:8] + feature_names[11:12] + feature_names[0:1] + feature_names[8:11]\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_map = {}\n",
    "for i, (_, v) in enumerate(category_map_tmp.items()):\n",
    "    category_map[i] = v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary with as keys the categorical columns and values the number of categories for each variable in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 9, 1: 7, 2: 4, 3: 9, 4: 6, 5: 5, 6: 2, 7: 11}\n"
     ]
    }
   ],
   "source": [
    "cat_vars_ord = {}\n",
    "n_categories = len(list(category_map.keys()))\n",
    "for i in range(n_categories):\n",
    "    cat_vars_ord[i] = len(np.unique(X[:, i]))\n",
    "print(cat_vars_ord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will apply one-hot encoding (OHE) on the categorical variables, we convert `cat_vars_ord` from the ordinal to OHE format. `alibi.utils.mapping` contains utility functions to do this. The keys in `cat_vars_ohe` now represent the first column index for each one-hot encoded categorical variable. This dictionary will later be used in the counterfactual explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 9, 9: 7, 16: 4, 20: 9, 29: 6, 35: 5, 40: 2, 42: 11}\n"
     ]
    }
   ],
   "source": [
    "cat_vars_ohe = ord_to_ohe(X, cat_vars_ord)[1]\n",
    "print(cat_vars_ohe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale numerical features between -1 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num = X[:, -4:].astype(np.float32, copy=False)\n",
    "xmin, xmax = X_num.min(axis=0), X_num.max(axis=0)\n",
    "rng = (-1., 1.)\n",
    "X_num_scaled = (X_num - xmin) / (xmax - xmin) * (rng[1] - rng[0]) + rng[0]\n",
    "X_num_scaled_train = X_num_scaled[:idx, :]\n",
    "X_num_scaled_test = X_num_scaled[idx+1:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply OHE to categorical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = X[:, :-4].copy()\n",
    "ohe = OneHotEncoder(categories='auto')\n",
    "ohe.fit(X_cat)\n",
    "X_cat_ohe = ohe.transform(X_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine numerical and categorical data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 57) (2560, 57)\n"
     ]
    }
   ],
   "source": [
    "X = np.c_[X_cat_ohe.todense(), X_num_scaled].astype(np.float32, copy=False)\n",
    "X_train, X_test = X[:idx, :], X[idx+1:, :]\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_ohe():\n",
    "    \n",
    "    x_in = Input(shape=(57,))\n",
    "    x = Dense(60, activation='relu')(x_in)\n",
    "    x = Dropout(.2)(x)\n",
    "    x = Dense(60, activation='relu')(x)\n",
    "    x = Dropout(.2)(x)\n",
    "    x = Dense(60, activation='relu')(x)\n",
    "    x = Dropout(.2)(x)\n",
    "    x_out = Dense(2, activation='softmax')(x)\n",
    "    \n",
    "    nn = Model(inputs=x_in, outputs=x_out)\n",
    "    nn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 57)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 60)                3480      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 122       \n",
      "=================================================================\n",
      "Total params: 10,922\n",
      "Trainable params: 10,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2d7cc5e410>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed()\n",
    "nn = nn_ohe()\n",
    "nn.summary()\n",
    "nn.fit(X_train, to_categorical(y_train), batch_size=256, epochs=30, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate counterfactual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_test[0].reshape((1,) + X_test[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize counterfactual parameters. The feature perturbations are applied in the numerical feature space, after transforming the categorical variables to numerical features. As a result, the dimensionality and values of `feature_range` are defined in the numerical space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = X.shape\n",
    "beta = .01\n",
    "c_init = 1.\n",
    "c_steps = 5\n",
    "max_iterations = 500\n",
    "rng = (-1., 1.)  # scale features between -1 and 1\n",
    "rng_shape = (1,) + data.shape[1:]\n",
    "feature_range = ((np.ones(rng_shape) * rng[0]).astype(np.float32), \n",
    "                 (np.ones(rng_shape) * rng[1]).astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize explainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(s=0):\n",
    "    np.random.seed(s)\n",
    "    tf.random.set_seed(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "cf = CounterFactualProto(nn,\n",
    "                         shape,\n",
    "                         beta=beta,\n",
    "                         cat_vars=cat_vars_ohe,\n",
    "                         ohe=True,  # OHE flag\n",
    "                         max_iterations=max_iterations,\n",
    "                         feature_range=feature_range,\n",
    "                         c_init=c_init,\n",
    "                         c_steps=c_steps\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit explainer. `d_type` refers to the distance metric used to convert the categorical to numerical values. Valid options are `abdm`, `mvdm` and `abdm-mvdm`. `abdm` infers the distance between categories of the same variable from the context provided by the other variables. This requires binning of the numerical features as well. `mvdm` computes the distance using the model predictions, and `abdm-mvdm` combines both methods. More info on both distance measures can be found in the [documentation](../doc/source/methods/CFProto.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf.fit(X_train, d_type='abdm', disc_perc=[25, 50, 75]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now visualize the transformation from the categorical to numerical values for each category. The example below shows that the **Education** feature is ordered from *High School Dropout* to having obtained a *Doctorate* degree. As a result, if we perturb an instance representing a person that has obtained a *Bachelors* degree, the nearest perturbations will result in a counterfactual instance with either a *Masters* or an *Associates* degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar(dist, cols, figsize=(10,4)):\n",
    "    dist = dist.reshape(dist.shape[0])\n",
    "    idx = np.argsort(dist)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    plt.bar(cols[idx], dist[idx])\n",
    "    print(cols[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dropout' 'High School grad' 'Associates' 'Bachelors' 'Masters'\n",
      " 'Prof-School' 'Doctorate']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat = 'Education'\n",
    "idx = feature_names.index(cat)\n",
    "plot_bar(cf.d_abs[idx], np.array(category_map[idx]), figsize=(20,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "explanation = cf.explain(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to more clearly describe explanations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_instance(X, explanation, eps=1e-2):\n",
    "    print('Original instance: {}  -- proba: {}'.format(target_names[explanation.orig_class],\n",
    "                                                       explanation.orig_proba[0]))\n",
    "    print('Counterfactual instance: {}  -- proba: {}'.format(target_names[explanation.cf['class']],\n",
    "                                                             explanation.cf['proba'][0]))\n",
    "    print('\\nCounterfactual perturbations...')\n",
    "    print('\\nCategorical:')\n",
    "    X_orig_ord = ohe_to_ord(X, cat_vars_ohe)[0]\n",
    "    X_cf_ord = ohe_to_ord(explanation.cf['X'], cat_vars_ohe)[0]\n",
    "    delta_cat = {}\n",
    "    for i, (_, v) in enumerate(category_map.items()):\n",
    "        cat_orig = v[int(X_orig_ord[0, i])]\n",
    "        cat_cf = v[int(X_cf_ord[0, i])]\n",
    "        if cat_orig != cat_cf:\n",
    "            delta_cat[feature_names[i]] = [cat_orig, cat_cf]\n",
    "    if delta_cat:\n",
    "        for k, v in delta_cat.items():\n",
    "            print('{}: {}  -->   {}'.format(k, v[0], v[1]))\n",
    "    print('\\nNumerical:')\n",
    "    delta_num = X_cf_ord[0, -4:] - X_orig_ord[0, -4:]\n",
    "    n_keys = len(list(cat_vars_ord.keys()))\n",
    "    for i in range(delta_num.shape[1]):\n",
    "        if np.abs(delta_num[0, i]) > eps:\n",
    "            print('{}: {:.2f}  -->   {:.2f}'.format(feature_names[i+n_keys],\n",
    "                                            X_orig_ord[0,i+n_keys],\n",
    "                                            X_cf_ord[0,i+n_keys]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original instance: <=50K  -- proba: [0.70744723 0.29255277]\n",
      "Counterfactual instance: >50K  -- proba: [0.37736374 0.62263626]\n",
      "\n",
      "Counterfactual perturbations...\n",
      "\n",
      "Categorical:\n",
      "Education: Associates  -->   Bachelors\n",
      "\n",
      "Numerical:\n"
     ]
    }
   ],
   "source": [
    "describe_instance(X, explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By obtaining a higher level of education the income is predicted to be above $50k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change the categorical distance metric\n",
    "\n",
    "Instead of `abdm`, we now use `mvdm` as our distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original instance: <=50K  -- proba: [0.70744723 0.29255277]\n",
      "Counterfactual instance: >50K  -- proba: [0.38161737 0.61838263]\n",
      "\n",
      "Counterfactual perturbations...\n",
      "\n",
      "Categorical:\n",
      "Education: Associates  -->   Bachelors\n",
      "\n",
      "Numerical:\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "cf.fit(X_train, d_type='mvdm')\n",
    "explanation = cf.explain(X)\n",
    "describe_instance(X, explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same conclusion hold using a different distance metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use k-d trees to build prototypes\n",
    "\n",
    "We can also use *k-d trees* to build class prototypes to guide the counterfactual to nearby instances in the counterfactual class as described in [Interpretable Counterfactual Explanations Guided by Prototypes](https://arxiv.org/abs/1907.02584). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_kdtree = True\n",
    "theta = 10.  # weight of prototype loss term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize, fit and explain instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original instance: <=50K  -- proba: [0.5211548  0.47884512]\n",
      "Counterfactual instance: >50K  -- proba: [0.49958408 0.500416  ]\n",
      "\n",
      "Counterfactual perturbations...\n",
      "\n",
      "Categorical:\n",
      "\n",
      "Numerical:\n",
      "Age: -0.53  -->   -0.51\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "X = X_test[7].reshape((1,) + X_test[0].shape)\n",
    "cf = CounterFactualProto(nn,\n",
    "                         shape,\n",
    "                         beta=beta,\n",
    "                         theta=theta,\n",
    "                         cat_vars=cat_vars_ohe,\n",
    "                         ohe=True,\n",
    "                         use_kdtree=use_kdtree,\n",
    "                         max_iterations=max_iterations,\n",
    "                         feature_range=feature_range,\n",
    "                         c_init=c_init,\n",
    "                         c_steps=c_steps\n",
    "                        )\n",
    "cf.fit(X_train, d_type='abdm')\n",
    "explanation = cf.explain(X)\n",
    "describe_instance(X, explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By slightly increasing the age of the person the income would be predicted to be above $50k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use an autoencoder to build prototypes\n",
    "\n",
    "Another option is to use an autoencoder to guide the perturbed instance to the counterfactual class. We define and train the autoencoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ae_model():\n",
    "    # encoder\n",
    "    x_in = Input(shape=(57,))\n",
    "    x = Dense(60, activation='relu')(x_in)\n",
    "    x = Dense(30, activation='relu')(x)\n",
    "    x = Dense(15, activation='relu')(x)\n",
    "    encoded = Dense(10, activation=None)(x)\n",
    "    encoder = Model(x_in, encoded)\n",
    "    \n",
    "    # decoder\n",
    "    dec_in = Input(shape=(10,))\n",
    "    x = Dense(15, activation='relu')(dec_in)\n",
    "    x = Dense(30, activation='relu')(x)\n",
    "    x = Dense(60, activation='relu')(x)\n",
    "    decoded = Dense(57, activation=None)(x)\n",
    "    decoder = Model(dec_in, decoded)\n",
    "    \n",
    "    # autoencoder = encoder + decoder\n",
    "    x_out = decoder(encoder(x_in))\n",
    "    autoencoder = Model(x_in, x_out)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    return autoencoder, encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 57)]              0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 10)                5935      \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 57)                5982      \n",
      "=================================================================\n",
      "Total params: 11,917\n",
      "Trainable params: 11,917\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2d783aff90>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed()\n",
    "ae, enc, dec = ae_model()\n",
    "ae.summary()\n",
    "ae.fit(X_train, X_train, batch_size=128, epochs=100, validation_data=(X_test, X_test), verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights for the autoencoder and prototype loss terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = .1  # L1\n",
    "gamma = 10.  # autoencoder\n",
    "theta = .1  # prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize, fit and explain instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original instance: >50K  -- proba: [0.48656026 0.5134398 ]\n",
      "Counterfactual instance: <=50K  -- proba: [0.71456206 0.28543794]\n",
      "\n",
      "Counterfactual perturbations...\n",
      "\n",
      "Categorical:\n",
      "Education: High School grad  -->   Dropout\n",
      "\n",
      "Numerical:\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "X = X_test[19].reshape((1,) + X_test[0].shape)\n",
    "cf = CounterFactualProto(nn,\n",
    "                         shape,\n",
    "                         beta=beta,\n",
    "                         enc_model=enc,\n",
    "                         ae_model=ae,\n",
    "                         gamma=gamma,\n",
    "                         theta=theta,\n",
    "                         cat_vars=cat_vars_ohe,\n",
    "                         ohe=True,\n",
    "                         max_iterations=max_iterations,\n",
    "                         feature_range=feature_range,\n",
    "                         c_init=c_init,\n",
    "                         c_steps=c_steps\n",
    "                        )\n",
    "cf.fit(X_train, d_type='abdm')\n",
    "explanation = cf.explain(X)\n",
    "describe_instance(X, explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Black box model with k-d trees\n",
    "\n",
    "Now we assume that we only have access to the model's prediction function and treat it as a black box. The k-d trees are again used to define the prototypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_kdtree = True\n",
    "theta = 10.  # weight of prototype loss term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize, fit and explain instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original instance: >50K  -- proba: [0.20676644 0.7932335 ]\n",
      "Counterfactual instance: <=50K  -- proba: [0.5048416  0.49515834]\n",
      "\n",
      "Counterfactual perturbations...\n",
      "\n",
      "Categorical:\n",
      "\n",
      "Numerical:\n",
      "Age: -0.15  -->   -0.19\n",
      "Hours per week: -0.20  -->   -0.51\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "\n",
    "X = X_test[24].reshape((1,) + X_test[0].shape)\n",
    "\n",
    "# define predict function\n",
    "predict_fn = lambda x: nn.predict(x)\n",
    "\n",
    "cf = CounterFactualProto(predict_fn,\n",
    "                         shape,\n",
    "                         beta=beta,\n",
    "                         theta=theta,\n",
    "                         cat_vars=cat_vars_ohe,\n",
    "                         ohe=True,\n",
    "                         use_kdtree=use_kdtree,\n",
    "                         max_iterations=max_iterations,\n",
    "                         feature_range=feature_range,\n",
    "                         c_init=c_init,\n",
    "                         c_steps=c_steps\n",
    "                        )\n",
    "cf.fit(X_train, d_type='abdm')\n",
    "explanation = cf.explain(X)\n",
    "describe_instance(X, explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the person was younger and worked less, he or she would have a predicted income below $50k."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
