dataset: movie_sentiment

# Example of configuring a random forest classifier
classifier:
  name: lr
  seed: 0
  solver: liblinear

# Example of configuring a AnchorTabular explainer
explainer:
  type: text
  threshold: 0.95
  pert_model: en_core_web_md  # spaCy model used for sentence perturbation
  use_unk: false
  use_similarity_proba: True
  sample_proba: 0.5
  temperature: 0.2
  top_n: 20
  parallel: false
  verbose: false
  seed: 0

# Experiment settings
experiment:
  test_only: false # disables saving output (avoid overwriting data when testing stuff)
  n_runs: 100
  instance_split: ~ # can be train/test/val or ~ (aka None - taken from data before splitting)
  instance_idx: 4
  ckpt_dir: /home/alex/git/work_experiments/BenchmarkTest
  ckpt: BenchmarkTestHashPassingExample2.pkl
  verbose: true
  show_covered: true
  data:
    preprocess: true
    preprocess_opts: # only used for text data for now
      min_df: 1
    split_opts:
      # train_test_val: uses sklearn.model.selection.train_test_split
      # shuffle: shuffles all data and puts first n_train_records in X_train
      method: train_test_val
      test_size: 0.2 # fraction of data in test split
      validation_set: true
      val_size: 0.1  # fraction of train split put into validation
      seed: 42       # same seed for split train/test and val from test
      n_train_records: 30000
  save:
    # elapsed time included by default
    fields: [feat_ids, feat_names, precision, coverage, covered_true, covered_false]
    # By default, it is assumed that the experiment object has
    # amongst its keys the values specified in fields. If this is
    # not the case, then mapping[fields[idx]] contains a list with
    # the keys that should be accessed in the experiment object to
    # retrieve the data. In this example, the output dictionary will be:
    # {'feat_ids': [[explanation['raw']['features'], ...],
    # 'feat_names':[[explanation['raw']['names'], ....]}
    # The lengths of the the keys are = n_runs
    mapping:
      feat_ids : [raw, feature]
      feat_names: [raw, names]
      covered_true: [raw, examples, covered_true]
      covered_false: [raw, examples, covered_false]
  profile: true
  profile_dir: /home/alex/git/work_experiments/ProfileData/dummy
  profile_out: benchmark_stats_text_use_unk_false_optimised.cprof
