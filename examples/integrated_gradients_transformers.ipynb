{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated gradients for transformers models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we apply the integrated gradients method to two different sentiment analysis models. The first model is a pretrained sentiment analysis model from the  [transformers](https://github.com/huggingface/transformers) library. The second model is a combination of a pretrained BERT model and a simple feed forward network. The feed forward network is trained on the IMDB dataset using the BERT output embeddings as features. \n",
    "\n",
    "In text classification models, integrated gradients define an attribution value for each word in the input sentence. The attributions are calculated considering the integral of the model  gradients with respect to the word embedding layer along a straight path from a baseline instance $x^\\prime$ to the input instance $x.$ A description of the method can be found [here](https://docs.seldon.io/projects/alibi/en/latest/methods/IntegratedGradients.html). Integrated gradients was originally proposed in Sundararajan et al., [\"Axiomatic Attribution for Deep Networks\"](https://arxiv.org/abs/1703.01365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import BertTokenizerFast, TFBertModel, BertConfig\n",
    "from alibi.explainers import IntegratedGradients\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.initializers import RandomUniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define some functions needed to process the data. For consistency with other [text examples](https://github.com/SeldonIO/alibi/blob/master/examples/integrated_gradients_imdb.ipynb) in alibi, we will use the IMDB dataset provided by keras. Since the dataset consists of reviews that are already tokenized, we need to decode each sentence and re-convert them into tokens using the BERT tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sentence(x, reverse_index):\n",
    "    \"\"\"Decodes the tokenized sentences from keras IMDB dataset into plain text.\n",
    "    \"\"\"\n",
    "    # the `-3` offset is due to the special tokens used by keras\n",
    "    # see https://stackoverflow.com/questions/42821330/restore-original-text-from-keras-s-imdb-dataset\n",
    "    return \" \".join([reverse_index.get(i - 3, 'UNK') for i in x])\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    \"\"\"Preprocess the text.\n",
    "    \"\"\"\n",
    "    REPLACE_NO_SPACE = re.compile(\"[.;:,!\\'?\\\"()\\[\\]]\")\n",
    "    REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "    \n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "def process_sentences(sentence, \n",
    "                      tokenizer, \n",
    "                      max_len):\n",
    "    \"\"\"Tokenize the text sentences.\n",
    "    \"\"\"\n",
    "    z = tokenizer(sentence, \n",
    "                  add_special_tokens = False, \n",
    "                  padding = 'max_length', \n",
    "                  max_length = max_len, \n",
    "                  truncation = True,\n",
    "                  return_token_type_ids=True, \n",
    "                  return_attention_mask = True,  \n",
    "                  return_tensors = 'np')\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will use the tensorflow auto model for sequence classification provided by the [transformers](https://github.com/huggingface/transformers) library. \n",
    "\n",
    "The model is pre-trained on the [Stanford Sentiment Treebank (SST)](https://huggingface.co/datasets/sst) dataset. The Stanford Sentiment Treebank is the first corpus with fully labeled parse trees that allows for a complete analysis of the compositional effects of sentiment in language.\n",
    "\n",
    "Each phrase is labelled as either negative, somewhat negative, neutral, somewhat positive or positive. The corpus with all 5 labels is referred to as SST-5 or SST fine-grained. Binary classification experiments on full sentences (negative or somewhat negative vs somewhat positive or positive with neutral sentences discarded) refer to the dataset as SST-2 or SST binary.  In this example, we will use a text classifier pre-trained on the SST-2 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "auto_model_bert = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The automodel output is a custom object containing the output logits. We use a wrapper to transform the output into a tensor and apply a softmax function to the logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoModelWrapper(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, model_bert, **kwargs):\n",
    "        super().__init__()\n",
    "        self.model_bert = model_bert\n",
    "\n",
    "    def call(self, inputs, attention_mask=None):\n",
    "        out = self.model_bert(inputs, \n",
    "                              attention_mask=attention_mask)\n",
    "        return tf.nn.softmax(out.logits)\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {}\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_model = AutoModelWrapper(auto_model_bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate integrated gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "max_len = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we consider some simple sentences such as \"I love you, I like you\", \"I love you, I like you, but I also kind of dislike you\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_test_sample = ['I love you, I like you',\n",
    "                'I love you, I like you, but I also kind of dislike you']\n",
    "z_test_sample = preprocess_reviews(z_test_sample)\n",
    "z_test_sample = process_sentences(z_test_sample, \n",
    "                                   tokenizer, \n",
    "                                   max_len)\n",
    "x_test_sample = z_test_sample['input_ids']\n",
    "kwargs = {k:v for k,v in z_test_sample.items() if k == 'attention_mask'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The auto model consists of a main BERT layer (layer 0) followed by two dense layers. \n",
    "We extract the first transformer's block in the main BERT layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertMainLayer at 0x7f1b51de3f50>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f1b5003f350>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f1b5003f710>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7f1b5003f950>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_model.layers[0].layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Extracting the first transformer block\n",
    "bl = auto_model.layers[0].layers[0].transformer.layer[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 5\n",
    "method = \"gausslegendre\"\n",
    "internal_batch_size = 5\n",
    "ig  = IntegratedGradients(auto_model,\n",
    "                          layer=bl,\n",
    "                          n_steps=n_steps, \n",
    "                          method=method,\n",
    "                          internal_batch_size=internal_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f1c5ad26670>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f1c5ad26670>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "predictions = auto_model(x_test_sample, **kwargs).numpy().argmax(axis=1)\n",
    "explanation = ig.explain(x_test_sample, \n",
    "                         forward_kwargs=kwargs,\n",
    "                         baselines=None, \n",
    "                         target=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributions shape: (2, 100, 768)\n"
     ]
    }
   ],
   "source": [
    "# Get attributions values from the explanation object\n",
    "attrs = explanation.attributions[0]\n",
    "print('Attributions shape:', attrs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributions shape: (2, 100)\n"
     ]
    }
   ],
   "source": [
    "attrs = attrs.sum(axis=2)\n",
    "print('Attributions shape:', attrs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "x_i = x_test_sample[i]\n",
    "attrs_i = attrs[i]\n",
    "pred = predictions[i]\n",
    "pred_dict = {1: 'Positive review', 0: 'Negative review'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "def  hlstr(string, color='white'):\n",
    "    \"\"\"\n",
    "    Return HTML markup highlighting text with the desired color.\n",
    "    \"\"\"\n",
    "    return f\"<mark style=background-color:{color}>{string} </mark>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorize(attrs, cmap='PiYG'):\n",
    "    \"\"\"\n",
    "    Compute hex colors based on the attributions for a single instance.\n",
    "    Uses a diverging colorscale by default and normalizes and scales\n",
    "    the colormap so that colors are consistent with the attributions.\n",
    "    \"\"\"\n",
    "    import matplotlib as mpl\n",
    "    cmap_bound = np.abs(attrs).max()\n",
    "    norm = mpl.colors.Normalize(vmin=-cmap_bound, vmax=cmap_bound)\n",
    "    cmap = mpl.cm.get_cmap(cmap)\n",
    "    \n",
    "    # now compute hex values of colors\n",
    "    colors = list(map(lambda x: mpl.colors.rgb2hex(cmap(norm(x))), attrs))\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = tokenizer.decode(x_i).split()\n",
    "colors = colorize(attrs_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label =  1: Positive review\n"
     ]
    }
   ],
   "source": [
    "print('Predicted label =  {}: {}'.format(pred, pred_dict[pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<mark style=background-color:#f9f1f5>i </mark><mark style=background-color:#276419>love </mark><mark style=background-color:#cfebaa>you </mark><mark style=background-color:#edf6e1>i </mark><mark style=background-color:#7dba40>like </mark><mark style=background-color:#e2f3ca>you </mark><mark style=background-color:#f8cee6>but </mark><mark style=background-color:#faebf3>i </mark><mark style=background-color:#b9e187>also </mark><mark style=background-color:#f3bdde>kind </mark><mark style=background-color:#faeaf2>of </mark><mark style=background-color:#e58dbe>dislike </mark><mark style=background-color:#bde38d>you </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\".join(list(map(hlstr, words, colors))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis on IMDB with fine-tuned model head."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider a text classifier fine-tuned on the IMDB dataset. We train a feed forward network which uses the pooled output embedding of a pretrained BERT model as input features. The BERT model and the trained ffn are combined to obtain an end-to-end text classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(X_train, model, batch_size=50):\n",
    "\n",
    "    args = X_train['input_ids']\n",
    "    kwargs = {k:v for k, v in  X_train.items() if k != 'input_ids'}\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((args, kwargs)).batch(batch_size)\n",
    "    dataset = dataset.as_numpy_iterator()\n",
    "    \n",
    "    embbedings = []\n",
    "    for X_batch in dataset:\n",
    "        args_b, kwargs_b = X_batch\n",
    "        batch_embeddings = model(args_b, **kwargs_b)\n",
    "        embbedings.append(batch_embeddings.pooler_output.numpy())\n",
    "\n",
    "    return np.concatenate(embbedings, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the IMDB dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "test_labels = y_test.copy()\n",
    "train_labels = y_train.copy()\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "index = imdb.get_word_index()\n",
    "reverse_index = {value: key for (key, value) in index.items()} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract embeddings for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to speed up the training, the BERT embeddings are pre-extracted and used as features by the feed forward network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
    "modelBert = TFBertModel.from_pretrained(\"bert-base-uncased\", config=config)\n",
    "\n",
    "modelBert.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_emb = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoding each sentence in the keras IMDB tokenized dataset to obtain the corresponding plain text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = [], []\n",
    "for i in range(len(x_train)):\n",
    "    tr_sentence = decode_sentence(x_train[i], reverse_index)\n",
    "    X_train.append(tr_sentence)\n",
    "    te_sentence = decode_sentence(x_test[i], reverse_index)\n",
    "    X_test.append(te_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-tokenizing the plain text using the BERT tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocess_reviews(X_train)\n",
    "X_train = process_sentences(X_train, tokenizer, max_len)\n",
    "X_test = preprocess_reviews(X_test)\n",
    "X_test = process_sentences(X_test, tokenizer, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the BERT embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embbedings = get_embeddings(X_train, \n",
    "                                  modelBert, \n",
    "                                  batch_size=batch_size_emb)\n",
    "test_embbedings = get_embeddings(X_test,\n",
    "                                 modelBert, \n",
    "                                 batch_size=batch_size_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we train the model head using the BERT pooled output embeddings as features. The pooled output embeddings are vectors of dimension 768 and each of them represents a full review. The model head consists of one dense layer 768 hidden units followed by a two units layer with softmax activation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.1\n",
    "hidden_dims = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelOut(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, \n",
    "                 dropout=0.2, \n",
    "                 hidden_dims=256):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout = dropout\n",
    "        self.hidden_dims = hidden_dims\n",
    "        \n",
    "        self.dense_1 =  tf.keras.layers.Dense(hidden_dims, \n",
    "                                              activation='relu')\n",
    "        self.dropoutl = tf.keras.layers.Dropout(dropout)\n",
    "        self.dense_2 = tf.keras.layers.Dense(2, \n",
    "                                             activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_1(inputs)\n",
    "        x = self.dropoutl(x)\n",
    "        x = self.dense_2(x)\n",
    "        return x\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {\"dropout\": self.dropout, \n",
    "                \"hidden_dims\": self.hidden_dims}\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out = ModelOut(dropout=dropout,\n",
    "                     hidden_dims=hidden_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model. If the model has been already trained, it can be loaded from the checkpoint directory setting `load_model=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = False\n",
    "batch_size = 128\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "191/196 [============================>.] - ETA: 0s - loss: 0.6712 - accuracy: 0.5844\n",
      "Epoch 00001: saving model to ./model_transformers/training/cp-0001.ckpt\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.6711 - accuracy: 0.5848 - val_loss: 0.6475 - val_accuracy: 0.6338\n",
      "Epoch 2/30\n",
      "184/196 [===========================>..] - ETA: 0s - loss: 0.6382 - accuracy: 0.6365\n",
      "Epoch 00002: saving model to ./model_transformers/training/cp-0002.ckpt\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.6382 - accuracy: 0.6364 - val_loss: 0.6288 - val_accuracy: 0.6437\n",
      "Epoch 3/30\n",
      "191/196 [============================>.] - ETA: 0s - loss: 0.6229 - accuracy: 0.6537\n",
      "Epoch 00003: saving model to ./model_transformers/training/cp-0003.ckpt\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.6234 - accuracy: 0.6530 - val_loss: 0.6159 - val_accuracy: 0.6645\n",
      "Epoch 4/30\n",
      "193/196 [============================>.] - ETA: 0s - loss: 0.6123 - accuracy: 0.6598\n",
      "Epoch 00004: saving model to ./model_transformers/training/cp-0004.ckpt\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.6119 - accuracy: 0.6602 - val_loss: 0.6058 - val_accuracy: 0.6679\n",
      "Epoch 5/30\n",
      "186/196 [===========================>..] - ETA: 0s - loss: 0.6058 - accuracy: 0.6688\n",
      "Epoch 00005: saving model to ./model_transformers/training/cp-0005.ckpt\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.6063 - accuracy: 0.6680 - val_loss: 0.6010 - val_accuracy: 0.6786\n",
      "Epoch 6/30\n",
      "187/196 [===========================>..] - ETA: 0s - loss: 0.5989 - accuracy: 0.6768\n",
      "Epoch 00006: saving model to ./model_transformers/training/cp-0006.ckpt\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.5986 - accuracy: 0.6774 - val_loss: 0.5955 - val_accuracy: 0.6848\n",
      "Epoch 7/30\n",
      "184/196 [===========================>..] - ETA: 0s - loss: 0.5985 - accuracy: 0.6766\n",
      "Epoch 00007: saving model to ./model_transformers/training/cp-0007.ckpt\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.5985 - accuracy: 0.6767 - val_loss: 0.5898 - val_accuracy: 0.6886\n",
      "Epoch 8/30\n",
      "191/196 [============================>.] - ETA: 0s - loss: 0.5931 - accuracy: 0.6816\n",
      "Epoch 00008: saving model to ./model_transformers/training/cp-0008.ckpt\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.5933 - accuracy: 0.6808 - val_loss: 0.5914 - val_accuracy: 0.6885\n",
      "Epoch 9/30\n",
      "179/196 [==========================>...] - ETA: 0s - loss: 0.5869 - accuracy: 0.6860\n",
      "Epoch 00009: saving model to ./model_transformers/training/cp-0009.ckpt\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.5886 - accuracy: 0.6848 - val_loss: 0.6056 - val_accuracy: 0.6634\n",
      "Epoch 10/30\n",
      "188/196 [===========================>..] - ETA: 0s - loss: 0.5869 - accuracy: 0.6868\n",
      "Epoch 00010: saving model to ./model_transformers/training/cp-0010.ckpt\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.5865 - accuracy: 0.6870 - val_loss: 0.6119 - val_accuracy: 0.6596\n",
      "Epoch 11/30\n",
      "188/196 [===========================>..] - ETA: 0s - loss: 0.5844 - accuracy: 0.6853\n",
      "Epoch 00011: saving model to ./model_transformers/training/cp-0011.ckpt\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.5850 - accuracy: 0.6852 - val_loss: 0.5905 - val_accuracy: 0.6866\n",
      "Epoch 12/30\n",
      "188/196 [===========================>..] - ETA: 0s - loss: 0.5819 - accuracy: 0.6910\n",
      "Epoch 00012: saving model to ./model_transformers/training/cp-0012.ckpt\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.5813 - accuracy: 0.6918 - val_loss: 0.5832 - val_accuracy: 0.6924\n",
      "Epoch 13/30\n",
      "189/196 [===========================>..] - ETA: 0s - loss: 0.5796 - accuracy: 0.6921\n",
      "Epoch 00013: saving model to ./model_transformers/training/cp-0013.ckpt\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.5788 - accuracy: 0.6932 - val_loss: 0.5803 - val_accuracy: 0.6924\n",
      "Epoch 14/30\n",
      "190/196 [============================>.] - ETA: 0s - loss: 0.5761 - accuracy: 0.6959\n",
      "Epoch 00014: saving model to ./model_transformers/training/cp-0014.ckpt\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.5768 - accuracy: 0.6950 - val_loss: 0.5867 - val_accuracy: 0.6830\n",
      "Epoch 15/30\n",
      "190/196 [============================>.] - ETA: 0s - loss: 0.5762 - accuracy: 0.6960\n",
      "Epoch 00015: saving model to ./model_transformers/training/cp-0015.ckpt\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.5761 - accuracy: 0.6958 - val_loss: 0.5752 - val_accuracy: 0.6981\n",
      "Epoch 16/30\n",
      "179/196 [==========================>...] - ETA: 0s - loss: 0.5745 - accuracy: 0.6981\n",
      "Epoch 00016: saving model to ./model_transformers/training/cp-0016.ckpt\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.5737 - accuracy: 0.6983 - val_loss: 0.5753 - val_accuracy: 0.6994\n",
      "Epoch 17/30\n",
      "189/196 [===========================>..] - ETA: 0s - loss: 0.5721 - accuracy: 0.6994\n",
      "Epoch 00017: saving model to ./model_transformers/training/cp-0017.ckpt\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.5727 - accuracy: 0.6992 - val_loss: 0.5724 - val_accuracy: 0.7027\n",
      "Epoch 18/30\n",
      "184/196 [===========================>..] - ETA: 0s - loss: 0.5706 - accuracy: 0.7020\n",
      "Epoch 00018: saving model to ./model_transformers/training/cp-0018.ckpt\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.5709 - accuracy: 0.7009 - val_loss: 0.5730 - val_accuracy: 0.7002\n",
      "Epoch 19/30\n",
      "189/196 [===========================>..] - ETA: 0s - loss: 0.5688 - accuracy: 0.7006\n",
      "Epoch 00019: saving model to ./model_transformers/training/cp-0019.ckpt\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.5699 - accuracy: 0.6996 - val_loss: 0.5853 - val_accuracy: 0.6864\n",
      "Epoch 20/30\n",
      "192/196 [============================>.] - ETA: 0s - loss: 0.5689 - accuracy: 0.7002\n",
      "Epoch 00020: saving model to ./model_transformers/training/cp-0020.ckpt\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.5689 - accuracy: 0.7005 - val_loss: 0.5701 - val_accuracy: 0.7039\n",
      "Epoch 21/30\n",
      "186/196 [===========================>..] - ETA: 0s - loss: 0.5687 - accuracy: 0.7014\n",
      "Epoch 00021: saving model to ./model_transformers/training/cp-0021.ckpt\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.5693 - accuracy: 0.7003 - val_loss: 0.5694 - val_accuracy: 0.7042\n",
      "Epoch 22/30\n",
      "190/196 [============================>.] - ETA: 0s - loss: 0.5644 - accuracy: 0.7027\n",
      "Epoch 00022: saving model to ./model_transformers/training/cp-0022.ckpt\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.5642 - accuracy: 0.7026 - val_loss: 0.5732 - val_accuracy: 0.6979\n",
      "Epoch 23/30\n",
      "178/196 [==========================>...] - ETA: 0s - loss: 0.5622 - accuracy: 0.7058\n",
      "Epoch 00023: saving model to ./model_transformers/training/cp-0023.ckpt\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.5623 - accuracy: 0.7061 - val_loss: 0.5747 - val_accuracy: 0.6938\n",
      "Epoch 24/30\n",
      "187/196 [===========================>..] - ETA: 0s - loss: 0.5624 - accuracy: 0.7090\n",
      "Epoch 00024: saving model to ./model_transformers/training/cp-0024.ckpt\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.5629 - accuracy: 0.7089 - val_loss: 0.5941 - val_accuracy: 0.6764\n",
      "Epoch 25/30\n",
      "186/196 [===========================>..] - ETA: 0s - loss: 0.5655 - accuracy: 0.7018\n",
      "Epoch 00025: saving model to ./model_transformers/training/cp-0025.ckpt\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.5654 - accuracy: 0.7022 - val_loss: 0.5663 - val_accuracy: 0.7060\n",
      "Epoch 26/30\n",
      "194/196 [============================>.] - ETA: 0s - loss: 0.5626 - accuracy: 0.7050\n",
      "Epoch 00026: saving model to ./model_transformers/training/cp-0026.ckpt\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.5623 - accuracy: 0.7053 - val_loss: 0.5647 - val_accuracy: 0.7080\n",
      "Epoch 27/30\n",
      "190/196 [============================>.] - ETA: 0s - loss: 0.5608 - accuracy: 0.7071\n",
      "Epoch 00027: saving model to ./model_transformers/training/cp-0027.ckpt\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.5610 - accuracy: 0.7067 - val_loss: 0.5757 - val_accuracy: 0.6918\n",
      "Epoch 28/30\n",
      "192/196 [============================>.] - ETA: 0s - loss: 0.5652 - accuracy: 0.7054\n",
      "Epoch 00028: saving model to ./model_transformers/training/cp-0028.ckpt\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.5651 - accuracy: 0.7054 - val_loss: 0.5647 - val_accuracy: 0.7082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "189/196 [===========================>..] - ETA: 0s - loss: 0.5574 - accuracy: 0.7097\n",
      "Epoch 00029: saving model to ./model_transformers/training/cp-0029.ckpt\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.5572 - accuracy: 0.7096 - val_loss: 0.5635 - val_accuracy: 0.7084\n",
      "Epoch 30/30\n",
      "175/196 [=========================>....] - ETA: 0s - loss: 0.5542 - accuracy: 0.7121\n",
      "Epoch 00030: saving model to ./model_transformers/training/cp-0030.ckpt\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.5551 - accuracy: 0.7112 - val_loss: 0.6014 - val_accuracy: 0.6726\n"
     ]
    }
   ],
   "source": [
    "filepath = './model_transformers/'  # change to desired save directory\n",
    "\n",
    "model_out.compile(optimizer=Adam(1e-4), \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "if not load_model:\n",
    "    \n",
    "    checkpoint_path = os.path.join(filepath, \"training/cp-{epoch:04d}.ckpt\")\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "    # Create a callback that saves the model's weights every epoch\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path, \n",
    "        verbose=1, \n",
    "        save_weights_only=True,\n",
    "        save_freq='epoch')\n",
    "\n",
    "    model_out.fit(train_embbedings, y_train, \n",
    "                  validation_data=(test_embbedings, y_test),\n",
    "                  epochs=epochs, \n",
    "                  batch_size=batch_size,\n",
    "                  callbacks=[cp_callback],\n",
    "                  verbose=1)\n",
    "else:\n",
    "    epoch = 3\n",
    "    load_path = os.path.join(filepath, f\"training/cp-{epoch:04d}.ckpt\")\n",
    "    model_out.load_weights(load_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine BERT and feed forward network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we combine the BERT model with the model head to obtain a end-to-end text classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, model_bert, model_out, **kwargs):\n",
    "        super().__init__()\n",
    "        self.model_bert = model_bert\n",
    "        self.model_out = model_out\n",
    "\n",
    "    def call(self, inputs, attention_mask=None):\n",
    "        out = self.model_bert(inputs, attention_mask=attention_mask)\n",
    "        out = self.model_out(out.pooler_output)\n",
    "        return out\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {}\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_classifier = TextClassifier(modelBert, model_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate integrated gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pick the first 10 sentences of the test set as examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_test_sample = [decode_sentence(x_test[i], reverse_index) for i in range(10)]\n",
    "z_test_sample = preprocess_reviews(z_test_sample)\n",
    "z_test_sample = process_sentences(z_test_sample, tokenizer, max_len)\n",
    "\n",
    "x_test_sample = z_test_sample['input_ids']\n",
    "kwargs = {k:v for k,v in z_test_sample.items() if k == 'attention_mask'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the attributions with respect to the first embedding layer of the BERT encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl = text_classifier.layers[0].bert.encoder.layer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 5\n",
    "method = \"gausslegendre\"\n",
    "internal_batch_size = 5\n",
    "ig  = IntegratedGradients(text_classifier,\n",
    "                          layer=bl,\n",
    "                          n_steps=n_steps, \n",
    "                          method=method,\n",
    "                          internal_batch_size=internal_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "predictions = text_classifier(x_test_sample, **kwargs).numpy().argmax(axis=1)\n",
    "explanation = ig.explain(x_test_sample, \n",
    "                         forward_kwargs=kwargs,\n",
    "                         baselines=None, \n",
    "                         target=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributions shape: (10, 100, 768)\n"
     ]
    }
   ],
   "source": [
    "# Get attributions values from the explanation object\n",
    "attrs = explanation.attributions[0]\n",
    "print('Attributions shape:', attrs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributions shape: (10, 100)\n"
     ]
    }
   ],
   "source": [
    "attrs = attrs.sum(axis=2)\n",
    "print('Attributions shape:', attrs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "x_i = x_test_sample[i]\n",
    "attrs_i = attrs[i]\n",
    "pred = predictions[i]\n",
    "pred_dict = {1: 'Positive review', 0: 'Negative review'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "def  hlstr(string, color='white'):\n",
    "    \"\"\"\n",
    "    Return HTML markup highlighting text with the desired color.\n",
    "    \"\"\"\n",
    "    return f\"<mark style=background-color:{color}>{string} </mark>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorize(attrs, cmap='PiYG'):\n",
    "    \"\"\"\n",
    "    Compute hex colors based on the attributions for a single instance.\n",
    "    Uses a diverging colorscale by default and normalizes and scales\n",
    "    the colormap so that colors are consistent with the attributions.\n",
    "    \"\"\"\n",
    "    import matplotlib as mpl\n",
    "    cmap_bound = np.abs(attrs).max()\n",
    "    norm = mpl.colors.Normalize(vmin=-cmap_bound, vmax=cmap_bound)\n",
    "    cmap = mpl.cm.get_cmap(cmap)\n",
    "    \n",
    "    # now compute hex values of colors\n",
    "    colors = list(map(lambda x: mpl.colors.rgb2hex(cmap(norm(x))), attrs))\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = tokenizer.decode(x_i).split()\n",
    "colors = colorize(attrs_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label =  1: Positive review\n"
     ]
    }
   ],
   "source": [
    "print('Predicted label =  {}: {}'.format(pred, pred_dict[pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<mark style=background-color:#acd977>a </mark><mark style=background-color:#69aa33>powerful </mark><mark style=background-color:#e9f5d8>study </mark><mark style=background-color:#ecf6de>of </mark><mark style=background-color:#f1f6e8>loneliness </mark><mark style=background-color:#eef6e2>sexual </mark><mark style=background-color:#f8f2f5>unk </mark><mark style=background-color:#f5f7f3>and </mark><mark style=background-color:#dff2c4>desperation </mark><mark style=background-color:#f5f7f2>be </mark><mark style=background-color:#f9eff4>patient </mark><mark style=background-color:#fbd9ec>unk </mark><mark style=background-color:#fbd8eb>up </mark><mark style=background-color:#f7f6f7>the </mark><mark style=background-color:#f7cce5>atmosphere </mark><mark style=background-color:#b9e187>and </mark><mark style=background-color:#dbf0bf>pay </mark><mark style=background-color:#86c049>attention </mark><mark style=background-color:#a5d56f>to </mark><mark style=background-color:#fce4f0>the </mark><mark style=background-color:#edf6e1>wonderfully </mark><mark style=background-color:#79b73d>written </mark><mark style=background-color:#eef6e2>script </mark><mark style=background-color:#eff6e4>br </mark><mark style=background-color:#eff6e5>br </mark><mark style=background-color:#fbe7f2>i </mark><mark style=background-color:#c51d7e>praise </mark><mark style=background-color:#f2b8db>robert </mark><mark style=background-color:#a7d672>altman </mark><mark style=background-color:#f9eef4>this </mark><mark style=background-color:#f7f7f6>is </mark><mark style=background-color:#6faf37>one </mark><mark style=background-color:#8fc654>of </mark><mark style=background-color:#eaf5d9>his </mark><mark style=background-color:#fcdded>many </mark><mark style=background-color:#edf6e1>films </mark><mark style=background-color:#edf6df>that </mark><mark style=background-color:#ecf6de>deals </mark><mark style=background-color:#f5f7f3>with </mark><mark style=background-color:#eaf5d9>unconventional </mark><mark style=background-color:#e8f5d5>fascinating </mark><mark style=background-color:#e7f5d3>subject </mark><mark style=background-color:#e8f5d5>matter </mark><mark style=background-color:#e4f4cd>this </mark><mark style=background-color:#d6eeb6>film </mark><mark style=background-color:#8cc551>is </mark><mark style=background-color:#cdeaa7>disturbing </mark><mark style=background-color:#e7f5d3>but </mark><mark style=background-color:#b5df82>its </mark><mark style=background-color:#f7f7f6>sincere </mark><mark style=background-color:#fbe9f2>and </mark><mark style=background-color:#fbe9f2>its </mark><mark style=background-color:#d9f0bc>sure </mark><mark style=background-color:#f8f2f5>to </mark><mark style=background-color:#f5f7f3>unk </mark><mark style=background-color:#f1f6ea>a </mark><mark style=background-color:#ebf6db>strong </mark><mark style=background-color:#f5f7f2>emotional </mark><mark style=background-color:#e4f4cd>response </mark><mark style=background-color:#f0f6e7>from </mark><mark style=background-color:#fbe8f2>the </mark><mark style=background-color:#f0f6e7>viewer </mark><mark style=background-color:#eff6e4>if </mark><mark style=background-color:#f8f5f6>you </mark><mark style=background-color:#f9f1f5>want </mark><mark style=background-color:#e8f5d5>to </mark><mark style=background-color:#c6e79c>see </mark><mark style=background-color:#faebf3>an </mark><mark style=background-color:#e7f5d2>unusual </mark><mark style=background-color:#f4f7f0>film </mark><mark style=background-color:#f3f6ed>some </mark><mark style=background-color:#fbe8f2>might </mark><mark style=background-color:#f7f7f6>even </mark><mark style=background-color:#f9f1f5>say </mark><mark style=background-color:#bbe28a>bizarre </mark><mark style=background-color:#f8f4f6>this </mark><mark style=background-color:#fbe6f1>is </mark><mark style=background-color:#fbe7f2>worth </mark><mark style=background-color:#f9eef4>the </mark><mark style=background-color:#f0f6e7>time </mark><mark style=background-color:#e8f5d5>br </mark><mark style=background-color:#f9d3e8>br </mark><mark style=background-color:#faedf3>unfortunately </mark><mark style=background-color:#fce3f0>its </mark><mark style=background-color:#e99cc8>very </mark><mark style=background-color:#900254>difficult </mark><mark style=background-color:#e9f5d8>to </mark><mark style=background-color:#b3126f>find </mark><mark style=background-color:#c4e699>in </mark><mark style=background-color:#fad4e9>video </mark><mark style=background-color:#f5f7f2>stores </mark><mark style=background-color:#f3f7ef>you </mark><mark style=background-color:#e590bf>may </mark><mark style=background-color:#ecf6de>have </mark><mark style=background-color:#f9f0f5>to </mark>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\".join(list(map(hlstr, words, colors))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
