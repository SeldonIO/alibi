{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%set_env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version:  2.3.1\n",
      "Eager execution enabled:  True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Conv1D, GlobalMaxPooling1D, Dropout \n",
    "from tensorflow.keras.layers import MaxPooling1D, Flatten, Activation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from alibi.explainers import IntegratedGradients\n",
    "from captum.attr import LayerIntegratedGradients, TokenReferenceBase\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "print('TF version: ', tf.__version__)\n",
    "print('Eager execution enabled: ', tf.executing_eagerly()) # True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "maxlen = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "test_labels = y_test.copy()\n",
    "train_labels = y_train.copy()\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "index = imdb.get_word_index()\n",
    "reverse_index = {value: key for (key, value) in index.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sentence(x, reverse_index):\n",
    "    # the `-3` offset is due to the special tokens used by keras\n",
    "    # see https://stackoverflow.com/questions/42821330/restore-original-text-from-keras-s-imdb-dataset\n",
    "    return \" \".join([reverse_index.get(i - 3, 'UNK') for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a powerful study of loneliness sexual UNK and desperation be patient UNK up the atmosphere and pay attention to the wonderfully written script br br i praise robert altman this is one of his many films that deals with unconventional fascinating subject matter this film is disturbing but it's sincere and it's sure to UNK a strong emotional response from the viewer if you want to see an unusual film some might even say bizarre this is worth the time br br unfortunately it's very difficult to find in video stores you may have to buy it off the internet\n"
     ]
    }
   ],
   "source": [
    "print(decode_sentence(x_test[1], reverse_index)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "hidden_dims = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.emb = nn.Embedding(max_features,\n",
    "                               embedding_dims)\n",
    "        self.linear1 = nn.Linear(5000, hidden_dims)\n",
    "        self.linear2 = nn.Linear(hidden_dims, 2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.emb(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear1(x)\n",
    "        # x = F.relu(x) # Adding relu layers makes the attributions different\n",
    "        x = self.linear2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "inputs = Input(shape=(maxlen,), \n",
    "               dtype='int32', \n",
    "               name='inputs')\n",
    "out = Embedding(max_features,\n",
    "                               embedding_dims, \n",
    "                               name='emb')(inputs)\n",
    "out = Flatten(name='Flat', data_format='channels_last')(out)\n",
    "out = Dense(hidden_dims, \n",
    "            name='linear1')(out)\n",
    "# out = Activation('relu')(out) # Adding relu layers makes the attributions different\n",
    "out = Dense(2, \n",
    "                name='linear2')(out)\n",
    "model = Model(inputs=inputs, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (emb): Embedding(10000, 50)\n",
       "  (linear1): Linear(in_features=5000, out_features=250, bias=True)\n",
       "  (linear2): Linear(in_features=250, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transfer weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnames = []\n",
    "for name in net.state_dict().keys():\n",
    "    lname = name.split('.')[0]\n",
    "    if lname not in lnames:\n",
    "        lnames.append(lname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb (10000, 50)\n",
      "linear1 (5000, 250)\n",
      "linear2 (250, 2)\n"
     ]
    }
   ],
   "source": [
    "for name in lnames:\n",
    "\n",
    "    if 'conv' in name:\n",
    "        ws = net.state_dict()[name + '.weight'].cpu().numpy()\n",
    "        ws = np.transpose(ws, (2, 1, 0))\n",
    "        bs = net.state_dict()[name + '.bias'].cpu().numpy()\n",
    "        l = model.get_layer(name)\n",
    "        l.set_weights([ws, bs])\n",
    "    elif 'linear' in name:\n",
    "        ws = net.state_dict()[name + '.weight'].cpu().numpy()\n",
    "        ws = ws.T\n",
    "        bs = net.state_dict()[name + '.bias'].cpu().numpy()\n",
    "        l = model.get_layer(name)\n",
    "        l.set_weights([ws, bs])\n",
    "    elif 'emb' in name:\n",
    "        ws = net.state_dict()[name + '.weight'].cpu().numpy()\n",
    "        l = model.get_layer(name)\n",
    "        l.set_weights([ws])\n",
    "    print(name, ws.shape) #  , bs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_emb_pt = net.state_dict()['emb.weight']\n",
    "weights_emb_tf = model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(weights_emb_pt, weights_emb_tf, rtol=1e-03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_samples = 10\n",
    "torch_X_test = torch.from_numpy(x_test)\n",
    "torch_y_test = torch.from_numpy(y_test)\n",
    "x_test_sample = torch_X_test[:nb_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\n",
       "array([[-0.0040464 ,  0.6038184 ],\n",
       "       [ 0.49326396, -0.3999495 ],\n",
       "       [-0.31098127,  0.08760172],\n",
       "       [ 0.39619875,  0.48363605],\n",
       "       [-0.2932438 ,  0.623353  ],\n",
       "       [-0.19899763,  0.08206717],\n",
       "       [ 0.1273778 ,  0.2847327 ],\n",
       "       [-0.20898356,  0.08907583],\n",
       "       [-0.37701988, -0.11866526],\n",
       "       [-0.6475955 ,  0.34030014]], dtype=float32)>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_test_sample.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0040,  0.6038],\n",
       "        [ 0.4933, -0.3999],\n",
       "        [-0.3110,  0.0876],\n",
       "        [ 0.3962,  0.4836],\n",
       "        [-0.2932,  0.6234],\n",
       "        [-0.1990,  0.0821],\n",
       "        [ 0.1274,  0.2847],\n",
       "        [-0.2090,  0.0891],\n",
       "        [-0.3770, -0.1187],\n",
       "        [-0.6476,  0.3403]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x_test_sample.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intgrads comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 50\n",
    "method = \"gausslegendre\"\n",
    "internal_batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_sentence(model, indexed, min_len = 100, label = 1):\n",
    "\n",
    "    input_indices = indexed.to(device)\n",
    "    seq_length = min_len\n",
    "\n",
    "    # predict\n",
    "    pred = net.forward(input_indices)\n",
    "\n",
    "    # generate reference indices for each sample\n",
    "    reference_indices = torch.tensor(np.zeros(input_indices.shape), dtype=int).to(device)\n",
    "\n",
    "    # compute attributions and approximation delta using layer integrated gradients\n",
    "    attributions_ig, delta = lig.attribute(input_indices, \n",
    "                                           reference_indices, \n",
    "                                           target=label,\n",
    "                                           method=method,\n",
    "                                           n_steps=50, \n",
    "                                           return_convergence_delta=True)\n",
    "    \n",
    "    return attributions_ig, delta, reference_indices.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "lig = LayerIntegratedGradients(net, net.emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributions shape: (10, 100, 50)\n"
     ]
    }
   ],
   "source": [
    "token_reference = TokenReferenceBase(reference_token_idx=0)\n",
    "# For simplicity, we compute the attribution relative to label = 1 for all samples\n",
    "attributions_pt, delta, reference_indices = interpret_sentence(net, \n",
    "                                                               x_test_sample, \n",
    "                                                               label=1)\n",
    "attributions_pt = attributions_pt.numpy()\n",
    "print('Attributions shape:', attributions_pt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.embeddings.Embedding at 0x7fbe97c2db10>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = model.layers[1]\n",
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig  = IntegratedGradients(model,\n",
    "                          layer=layer,\n",
    "                          n_steps=n_steps, \n",
    "                          method=method,\n",
    "                          internal_batch_size=internal_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_sample = x_test_sample.numpy()\n",
    "predictions = model(x_test_sample).numpy().argmax(axis=1)\n",
    "explanation = ig.explain(x_test_sample, \n",
    "                         baselines=reference_indices, \n",
    "                         target=1)\n",
    "# Get attributions values from the explanation object\n",
    "attributions_tf = explanation.attributions[0]\n",
    "print('Attributions shape:', attributions_tf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(attributions_tf, attributions_pt, rtol=1e-03)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:intgrads] *",
   "language": "python",
   "name": "conda-env-intgrads-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
